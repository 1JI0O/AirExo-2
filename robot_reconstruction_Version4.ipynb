{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单臂机器人 3D 重建 (基于 AirExo-2)\n",
    "\n",
    "本 Notebook 使用 AirExo-2 代码库的原生函数,从 lowdim 数据和标定数据重建机器人的 3D 模型并进行渲染。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# # 添加 AirExo-2 到 Python 路径\n",
    "# AIREXO_PATH = \"/path/to/AirExo-2\"  # 修改为你的 AirExo-2 路径\n",
    "# sys.path.insert(0, AIREXO_PATH)\n",
    "\n",
    "# 导入 AirExo-2 模块\n",
    "from airexo.helpers.urdf_robot import forward_kinematic_single\n",
    "from airexo.helpers.constants import ROBOT_PREDEFINED_TRANSFORMATION, O3D_RENDER_TRANSFORMATION\n",
    "from airexo.helpers.renderer import RobotRenderer\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "print(\"✓ 所有库导入成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 数据路径配置 =====\n",
    "SCENE_PATH = \"/data/haoxiang/data/FLIPPING_v3/train/scene_0001\"\n",
    "LOWDIM_H5_PATH = os.path.join(SCENE_PATH, \"lowdim/lowdim.h5\")\n",
    "\n",
    "# ===== 标定数据 =====\n",
    "# pose_in_link: 7 维 [x, y, z, qx, qy, qz, qw]，表示【相机在机械臂 base 下的位姿】\n",
    "CALIB_DATA = {\n",
    "    \"is_global\": True,\n",
    "    \"pose_in_link\": [\n",
    "        0.07783932332093665,\n",
    "        0.2078814260418823,\n",
    "        0.34723683952957585,\n",
    "        0.2273133855008057,\n",
    "        -0.6785647482083789,\n",
    "        0.6637673415778982,\n",
    "        -0.21746591345696367\n",
    "    ],\n",
    "    \"error\": 0.0024148397685646483,\n",
    "    \"parent_link_name\": \"world\",\n",
    "    \"cam_serial\": \"104122060902\",\n",
    "    \"intrinsics\": [\n",
    "        [915.384521484375, 0.0, 633.3715209960938],\n",
    "        [0.0, 914.9421997070312, 354.1505432128906],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ===== URDF 配置 =====\n",
    "# 使用 AirExo-2 仓库中的 URDF 文件\n",
    "# URDF_FILE = os.path.join(AIREXO_PATH, \"airexo/urdf_models/robot/left_robot_inhand.urdf\")\n",
    "URDF_FILE = \"airexo/urdf_models/robot/left_robot_inhand.urdf\"\n",
    "\n",
    "# ===== 关节配置 =====\n",
    "# 加载 AirExo-2 的关节配置文件\n",
    "# JOINT_CFG_PATH = os.path.join(AIREXO_PATH, \"airexo/configs/joint/left/robot.yaml\")\n",
    "JOINT_CFG_PATH = \"airexo/configs/joint/left/robot.yaml\"\n",
    "\n",
    "print(f\"场景路径: {SCENE_PATH}\")\n",
    "print(f\"Lowdim 数据: {LOWDIM_H5_PATH}\")\n",
    "print(f\"URDF 文件: {URDF_FILE}\")\n",
    "print(f\"关节配置: {JOINT_CFG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRobotData:\n",
    "    \"\"\"单臂机器人数据加载器\"\"\"\n",
    "    \n",
    "    def __init__(self, lowdim_h5_path, calib_data, joint_cfg_path, urdf_file):\n",
    "        self.lowdim_h5_path = lowdim_h5_path\n",
    "        self.calib_data = calib_data\n",
    "        self.urdf_file = urdf_file\n",
    "        \n",
    "        # 加载关节配置\n",
    "        self.joint_cfgs = OmegaConf.load(joint_cfg_path)\n",
    "        \n",
    "        # 加载 lowdim 数据\n",
    "        self._load_lowdim_data()\n",
    "        \n",
    "        # 处理标定数据\n",
    "        self._process_calibration()\n",
    "        \n",
    "    def _load_lowdim_data(self):\n",
    "        \"\"\"加载 HDF5 lowdim 数据\"\"\"\n",
    "        print(f\"\\n📂 加载 lowdim 数据: {self.lowdim_h5_path}\")\n",
    "        \n",
    "        with h5py.File(self.lowdim_h5_path, 'r') as f:\n",
    "            print(f\"\\n数据集结构:\")\n",
    "            for key in f.keys():\n",
    "                print(f\"  - {key}: shape={f[key].shape}, dtype={f[key].dtype}\")\n",
    "            \n",
    "            # 读取关节位置 (弧度)\n",
    "            self.joint_positions = f['joint_position_rad_062046'][:]  # (N, 7)\n",
    "            \n",
    "            # 读取末端执行器状态 (夹爪)\n",
    "            self.ee_states = f['ee_state_062046'][:]  # (N, 1)\n",
    "            \n",
    "            # 读取时间戳\n",
    "            self.timestamps = f['timestamp'][:]  # (N,)\n",
    "            \n",
    "            # 读取 TCP 位姿 (用于验证)\n",
    "            if 'tcp_pose_062046' in f:\n",
    "                self.tcp_poses = f['tcp_pose_062046'][:]  # (N, 7)\n",
    "        \n",
    "        print(f\"\\n✓ 加载了 {len(self.timestamps)} 帧数据\")\n",
    "        print(f\"  - 关节位置: {self.joint_positions.shape}\")\n",
    "        print(f\"  - 夹爪状态: {self.ee_states.shape}\")\n",
    "        \n",
    "    def _process_calibration(self):\n",
    "        \"\"\"标定：pose_in_link 为 7 维 [x,y,z,qx,qy,qz,qw]，表示相机在机械臂 base 下的位姿。\"\"\"\n",
    "        print(f\"\\n🎯 处理标定数据...\")\n",
    "        self.intrinsic = np.array(self.calib_data['intrinsics'], dtype=np.float32)\n",
    "        pose_in_link = self.calib_data['pose_in_link']\n",
    "        position = np.array(pose_in_link[:3])   # 相机原点在机械臂 base 下的坐标\n",
    "        quaternion = np.array(pose_in_link[3:]) # [x,y,z,w] scipy 四元数约定\n",
    "        \n",
    "        R = Rotation.from_quat(quaternion).as_matrix()\n",
    "        # T_cam_to_base: 点从相机系变换到机械臂底座系，p_base = R @ p_cam + position\n",
    "        self.cam_to_base = np.eye(4, dtype=np.float32)\n",
    "        self.cam_to_base[:3, :3] = R\n",
    "        self.cam_to_base[:3, 3] = position\n",
    "        self.base_to_cam = np.linalg.inv(self.cam_to_base).astype(np.float32)\n",
    "        print(f\"相机在机械臂 base 下的位置: {position}\")\n",
    "        print(f\"cam_to_base (相机系→底座系):\\n{self.cam_to_base}\")\n",
    "\n",
    "\n",
    "        \n",
    "    def get_joint_at_timestamp(self, timestamp_idx):\n",
    "        \"\"\"获取指定时间戳的关节数据\"\"\"\n",
    "        # 7个机器人关节 + 1个夹爪\n",
    "        joint_angles = self.joint_positions[timestamp_idx]  # (7,)\n",
    "        ee_state = self.ee_states[timestamp_idx, 0]  # 夹爪宽度\n",
    "        \n",
    "        # 合并为完整的关节状态\n",
    "        full_joint = np.concatenate([joint_angles, [ee_state]], axis=0)\n",
    "        \n",
    "        return full_joint\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "robot_data = SingleRobotData(\n",
    "    lowdim_h5_path=LOWDIM_H5_PATH,\n",
    "    calib_data=CALIB_DATA,\n",
    "    joint_cfg_path=JOINT_CFG_PATH,\n",
    "    urdf_file=URDF_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 正向运动学重建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_robot_at_frame(robot_data, frame_idx):\n",
    "    \"\"\"\n",
    "    在指定帧重建机器人 3D 模型\n",
    "    \n",
    "    参数:\n",
    "        robot_data: 数据加载器对象\n",
    "        frame_idx: 帧索引\n",
    "        \n",
    "    返回:\n",
    "        transforms: link 变换字典\n",
    "        visuals_map: 视觉模型映射\n",
    "        meshes: 变换后的网格列表\n",
    "    \"\"\"\n",
    "    print(f\"\\n🤖 重建帧 {frame_idx} (时间戳: {robot_data.timestamps[frame_idx]})\")\n",
    "    \n",
    "    # 获取该帧的关节状态\n",
    "    joint_state = robot_data.get_joint_at_timestamp(frame_idx)\n",
    "    print(f\"关节状态 (rad): {joint_state[:7]}\")\n",
    "    print(f\"夹爪宽度: {joint_state[7]:.4f} m\")\n",
    "    \n",
    "    # 使用 AirExo-2 的正向运动学函数\n",
    "    print(\"\\n执行正向运动学...\")\n",
    "    transforms, visuals_map = forward_kinematic_single(\n",
    "        joint=joint_state,\n",
    "        joint_cfgs=robot_data.joint_cfgs,\n",
    "        is_rad=True,  # 数据已经是弧度\n",
    "        urdf_file=robot_data.urdf_file,\n",
    "        with_visuals_map=True\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ 计算了 {len(transforms)} 个 link 的变换\")\n",
    "    \n",
    "    # 加载并变换 3D 网格\n",
    "    print(\"\\n加载 3D 网格...\")\n",
    "    meshes = []\n",
    "    urdf_dir = os.path.dirname(robot_data.urdf_file)\n",
    "    \n",
    "    for link_name, transform in transforms.items():\n",
    "        visuals = visuals_map.get(link_name, [])\n",
    "        \n",
    "        for visual in visuals:\n",
    "            if visual.geom_param is None:\n",
    "                continue\n",
    "            \n",
    "            # 获取网格文件路径\n",
    "            mesh_file = visual.geom_param\n",
    "            if isinstance(mesh_file, (list, tuple)):\n",
    "                mesh_file = mesh_file[0]\n",
    "            \n",
    "            mesh_path = os.path.join(urdf_dir, mesh_file)\n",
    "            \n",
    "            if not os.path.exists(mesh_path):\n",
    "                print(f\"⚠️  网格文件不存在: {mesh_path}\")\n",
    "                continue\n",
    "            \n",
    "            # 变换链：mesh 在机械臂底座系 (visual_offset → link → ROBOT_PREDEFINED)\n",
    "            tf = ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                 transform.matrix() @ \\\n",
    "                 visual.offset.matrix()\n",
    "                 \n",
    "            \n",
    "            # 加载网格\n",
    "            mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "            mesh.transform(tf)\n",
    "            mesh.compute_vertex_normals()\n",
    "            mesh.paint_uniform_color([0.7, 0.7, 0.7])  # 灰色\n",
    "            \n",
    "            meshes.append({\n",
    "                'link_name': link_name,\n",
    "                'mesh_file': mesh_file,\n",
    "                'mesh': mesh,\n",
    "                'transform': tf\n",
    "            })\n",
    "            \n",
    "            print(f\"  ✓ {link_name}: {os.path.basename(mesh_file)}\")\n",
    "    \n",
    "    print(f\"\\n✓ 成功加载 {len(meshes)} 个网格\")\n",
    "    \n",
    "    return transforms, visuals_map, meshes\n",
    "\n",
    "\n",
    "# 测试重建\n",
    "FRAME_IDX = 0\n",
    "transforms, visuals_map, meshes = reconstruct_robot_at_frame(robot_data, FRAME_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 3D 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "# import numpy as np\n",
    "\n",
    "def visualize_robot_3d_k3d(meshes, show_coordinate_frame=True):\n",
    "    \"\"\"\n",
    "    使用 K3D 在 Jupyter 中实现丝滑的 3D 可视化\n",
    "    \"\"\"\n",
    "    # 1. 创建 Plot 对象\n",
    "    # grid_visible: 是否显示网格\n",
    "    # camera_auto_fit: 自动调整相机视角以容纳所有物体\n",
    "    plot = k3d.plot(grid_visible=True, \n",
    "                    grid=[ -1, -1, -1, 1, 1, 1], # 网格范围\n",
    "                    background_color=0xffffff,   # 白色背景\n",
    "                    menu_visibility=True)        # 显示右上角控制面板\n",
    "\n",
    "    # 2. 添加坐标系 (X-红, Y-绿, Z-蓝)\n",
    "    if show_coordinate_frame:\n",
    "        axis_length = 0.2\n",
    "        # 提取原始位置和姿态\n",
    "        origin = ROBOT_PREDEFINED_TRANSFORMATION[:3, 3].astype(np.float32)\n",
    "        rot = ROBOT_PREDEFINED_TRANSFORMATION[:3, :3].astype(np.float32)\n",
    "        \n",
    "        # 定义轴的终点\n",
    "        x_end = origin + rot[:, 0] * axis_length\n",
    "        y_end = origin + rot[:, 1] * axis_length\n",
    "        z_end = origin + rot[:, 2] * axis_length\n",
    "\n",
    "        # K3D 中画线段代表坐标轴\n",
    "        plot += k3d.line(np.stack([origin, x_end]), color=0xff0000, width=0.01, name=\"X-axis\")\n",
    "        plot += k3d.line(np.stack([origin, y_end]), color=0x00ff00, width=0.01, name=\"Y-axis\")\n",
    "        plot += k3d.line(np.stack([origin, z_end]), color=0x0000ff, width=0.01, name=\"Z-axis\")\n",
    "\n",
    "    # 3. 添加机器人网格\n",
    "    # K3D 颜色需要十六进制整数\n",
    "    hex_colors = [0xcccccc, 0xaaaaaa, 0x888888, 0x666666, 0x444444]\n",
    "    \n",
    "    for i, mesh_data in enumerate(meshes):\n",
    "        mesh = mesh_data['mesh']\n",
    "        \n",
    "        # 转换顶点和面片索引为 K3D 要求的格式 (float32 和 uint32)\n",
    "        vertices = np.asarray(mesh.vertices).astype(np.float32)\n",
    "        indices = np.asarray(mesh.triangles).astype(np.uint32)\n",
    "        \n",
    "        # 创建 K3D 网格对象\n",
    "        k3d_mesh = k3d.mesh(vertices, indices, \n",
    "                            color=hex_colors[i % len(hex_colors)],\n",
    "                            name=mesh_data['link_name'],\n",
    "                            opacity=1.0,  # K3D 的渲染性能很好，建议用不透明\n",
    "                            side='double') # 双面渲染，防止法线反转看不见\n",
    "        \n",
    "        plot += k3d_mesh\n",
    "        print(f\"  ✓ 添加网格: {mesh_data['link_name']}\")\n",
    "\n",
    "    # 4. 显示\n",
    "    plot.display()\n",
    "    \n",
    "    # 打印操作说明\n",
    "    print(\"\\n🎮 K3D 操作指南:\")\n",
    "    print(\"  - 左键拖拽: 自由旋转 (Trackball 模式，无角度限制)\")\n",
    "    print(\"  - 右键拖拽: 平移 (Pan)\")\n",
    "    print(\"  - 滚轮: 缩放 (Zoom)\")\n",
    "    print(\"  - 右上角菜单: 可以手动调节每个 Link 的可见性和颜色\")\n",
    "    \n",
    "    return plot\n",
    "\n",
    "# 运行可视化\n",
    "plot_instance = visualize_robot_3d_k3d(meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 渲染 RGB 图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_robot_image(robot_data, meshes, width=1280, height=720):\n",
    "    \"\"\"将底座系下的 mesh 经 base_to_cam 变换到相机系后，用内参渲染为 RGB/深度图。\"\"\"\n",
    "    print(f\"\\n🎨 渲染 {width}x{height} 图像...\")\n",
    "    \n",
    "    # 创建 Open3D 离屏渲染器\n",
    "    renderer = o3d.visualization.rendering.OffscreenRenderer(width, height)\n",
    "    \n",
    "    # 设置材质\n",
    "    material = o3d.visualization.rendering.MaterialRecord()\n",
    "    material.shader = \"defaultLit\"\n",
    "    \n",
    "    # 添加网格到场景 (应用相机变换)\n",
    "    for i, mesh_data in enumerate(meshes):\n",
    "        # 复制网格避免修改原始数据\n",
    "        mesh = mesh_data['mesh']\n",
    "        mesh_copy = o3d.geometry.TriangleMesh(mesh)\n",
    "        \n",
    "        # 将 mesh 从底座系变换到相机系，再应用 Open3D 渲染坐标系约定\n",
    "        mesh_copy.transform(O3D_RENDER_TRANSFORMATION @ robot_data.base_to_cam)\n",
    "        \n",
    "        renderer.scene.add_geometry(f\"mesh_{i}\", mesh_copy, material)\n",
    "    \n",
    "    # 设置相机投影\n",
    "    renderer.scene.camera.set_projection(\n",
    "        robot_data.intrinsic,\n",
    "        0.01,    # near_plane\n",
    "        100.0,   # far_plane\n",
    "        float(width),\n",
    "        float(height)\n",
    "    )\n",
    "    \n",
    "    # 渲染\n",
    "    rgb_image = np.asarray(renderer.render_to_image(), dtype=np.uint8)\n",
    "    depth_image = np.asarray(\n",
    "        renderer.render_to_depth_image(z_in_view_space=True),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ 渲染完成: RGB {rgb_image.shape}, Depth {depth_image.shape}\")\n",
    "    \n",
    "    return rgb_image, depth_image\n",
    "\n",
    "\n",
    "# 渲染图像\n",
    "rgb_image, depth_image = render_robot_image(robot_data, meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 显示渲染结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示 RGB 图像\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# RGB\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb_image)\n",
    "plt.title(f\"Rendered RGB Image - Frame {FRAME_IDX}\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Depth (归一化)\n",
    "plt.subplot(1, 2, 2)\n",
    "depth_vis = depth_image.copy()\n",
    "depth_vis[depth_vis == np.inf] = 0\n",
    "depth_vis = (depth_vis / depth_vis.max() * 255).astype(np.uint8)\n",
    "plt.imshow(depth_vis, cmap='jet')\n",
    "plt.title(f\"Rendered Depth Map - Frame {FRAME_IDX}\")\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print(f\"\\n💾 保存图像...\")\n",
    "# Image.fromarray(rgb_image).save(f\"robot_render_frame_{FRAME_IDX}.png\")\n",
    "# print(f\"✓ 已保存: robot_render_frame_{FRAME_IDX}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机械臂和点云对照查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☁️ 生成点云（相机坐标系）...\n",
      "🤖 FK 计算机器人并映射到相机系...\n",
      "\n",
      "🤖 重建帧 0 (时间戳: 1767593840232)\n",
      "关节状态 (rad): [ 0.6657125  -1.0406699  -1.9467313   2.145058    1.6500233   0.39253008\n",
      "  1.2164255 ]\n",
      "夹爪宽度: 0.0002 m\n",
      "\n",
      "执行正向运动学...\n",
      "✓ 计算了 18 个 link 的变换\n",
      "\n",
      "加载 3D 网格...\n",
      "  ✓ base_link: link0.obj\n",
      "  ✓ link1: link1.obj\n",
      "  ✓ link2: link2.obj\n",
      "  ✓ link3: link3.obj\n",
      "  ✓ link4: link4.obj\n",
      "  ✓ link5: link5.obj\n",
      "  ✓ link6: link6.obj\n",
      "  ✓ link7: link7_inhand_l.stl\n",
      "  ✓ robotiq_2f85_base_link: robotiq_2f85_base_link.stl\n",
      "  ✓ left_outer_knuckle: outer_knuckle.stl\n",
      "  ✓ left_outer_finger: outer_finger.stl\n",
      "  ✓ left_inner_knuckle: inner_knuckle.stl\n",
      "  ✓ left_inner_finger: inner_finger.stl\n",
      "  ✓ right_inner_knuckle: inner_knuckle.stl\n",
      "  ✓ right_inner_finger: inner_finger.stl\n",
      "  ✓ right_outer_knuckle: outer_knuckle.stl\n",
      "  ✓ right_outer_finger: outer_finger.stl\n",
      "\n",
      "✓ 成功加载 17 个网格\n",
      "🎨 正在构建 K3D 场景...\n",
      "🔧 应用 YOZ 平面镜像 (X -> -X)...\n",
      "🔧 增加旋转: 绕 X 轴旋转 45 度...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edd495e7ff1487d9a218ce233329765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成。点云与机器人均在相机坐标系下；红色为 FK 机器人（经 base_to_cam 映射到相机系）。\n"
     ]
    }
   ],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def debug_alignment_k3d(robot_data, frame_idx, rgb_path, depth_path, subsample_step=4):\n",
    "    \"\"\"\n",
    "    在 K3D 中同时显示（均在相机坐标系下）：\n",
    "    1. 深度图反投影得到的点云（不做变换，保持相机系）\n",
    "    2. FK 机器人模型经 base_to_cam 映射到相机系后的 mesh\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== 1. 点云：深度反投影到相机系，不再做任何变换 ==========\n",
    "    print(\"☁️ 生成点云（相机坐标系）...\")\n",
    "    \n",
    "    # 加载图像\n",
    "    color_img = cv2.cvtColor(cv2.imread(rgb_path), cv2.COLOR_BGR2RGB)\n",
    "    depth_img = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "    \n",
    "    # 获取内参\n",
    "    K = robot_data.intrinsic\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    \n",
    "    # 降采样 (为了 K3D 流畅度，每隔 4 个像素取一个点)\n",
    "    # 注意：K3D处理百万级点云会卡顿，建议采样\n",
    "    v_idx, u_idx = np.indices(depth_img.shape)\n",
    "    v_idx = v_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    u_idx = u_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    z = depth_img[::subsample_step, ::subsample_step].flatten()\n",
    "    colors = color_img[::subsample_step, ::subsample_step].reshape(-1, 3)\n",
    "    \n",
    "    # 简单的深度过滤 (去掉无效点和太远的点)\n",
    "    valid_mask = (z > 0) & (z < 2000) # 假设单位是毫米，2米以内\n",
    "    u_idx = u_idx[valid_mask]\n",
    "    v_idx = v_idx[valid_mask]\n",
    "    z = z[valid_mask]\n",
    "    colors = colors[valid_mask]\n",
    "    \n",
    "    # 如果深度单位是毫米，转为米 (URDF通常是米)\n",
    "    # 请根据你的实际数据确认 scale！通常 realsense 是 1000.0\n",
    "    scale = 1000.0 \n",
    "    z_m = z / scale\n",
    "    \n",
    "    # 反投影到相机坐标系 (Camera Frame)\n",
    "    x_m = (u_idx - cx) * z_m / fx\n",
    "    y_m = (v_idx - cy) * z_m / fy\n",
    "    \n",
    "    points_cam = np.stack([x_m, y_m, z_m], axis=1)  # 保持相机系，不变换\n",
    "    \n",
    "    r = colors[:, 0].astype(np.uint32)\n",
    "    g = colors[:, 1].astype(np.uint32)\n",
    "    b = colors[:, 2].astype(np.uint32)\n",
    "    colors_int = (r << 16) | (g << 8) | b\n",
    "\n",
    "    # ========== 2. 机器人 mesh（底座系）并映射到相机系 ==========\n",
    "    print(\"🤖 FK 计算机器人并映射到相机系...\")\n",
    "    \n",
    "    _, _, meshes_data = reconstruct_robot_at_frame(robot_data, frame_idx)\n",
    "\n",
    "    # --- 核心修改部分 ---\n",
    "    # 获取原始的平移向量 (相机坐标系下 Base 的位置)\n",
    "    t_base_in_cam = robot_data.base_to_cam[:3, 3]\n",
    "    \n",
    "    # 构造一个新的变换矩阵：旋转部分设为单位阵，平移保持不变\n",
    "    base_to_cam_no_rot = np.eye(4, dtype=np.float32)\n",
    "    base_to_cam_no_rot[:3, 3] = t_base_in_cam\n",
    "    # ------------------\n",
    "    \n",
    "    # ==============================\n",
    "    # 3. K3D 可视化\n",
    "    # ==============================\n",
    "    print(\"🎨 正在构建 K3D 场景...\")\n",
    "    plot = k3d.plot(background_color=0xFFFFFF) \n",
    "    \n",
    "    # A. 点云（相机系，不变换）\n",
    "    cloud_plt = k3d.points(\n",
    "        positions=points_cam.astype(np.float32),\n",
    "        colors=colors_int.astype(np.uint32),\n",
    "        point_size=0.005, shader='flat', name=\"Point Cloud (camera)\"\n",
    "    )\n",
    "    plot += cloud_plt\n",
    "\n",
    "    # ==============================\n",
    "    # 核心修改：针对 YOZ 平面镜像 (Flip X)\n",
    "    # ==============================\n",
    "    print(\"🔧 应用 YOZ 平面镜像 (X -> -X)...\")\n",
    "    \n",
    "    # 1. 获取原始矩阵\n",
    "    T_base_to_cam = robot_data.base_to_cam\n",
    "    R_orig = T_base_to_cam[:3, :3]\n",
    "    t_orig = T_base_to_cam[:3, 3]\n",
    "    \n",
    "    # ==============================\n",
    "    # 1. 之前的步骤：YOZ 平面镜像 (Flip X)\n",
    "    # ==============================\n",
    "    mirror_mat = np.array([\n",
    "        [-1, 0, 0],\n",
    "        [ 0, 1, 0],\n",
    "        [ 0, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # 先计算镜像后的中间状态\n",
    "    R_mirrored = mirror_mat @ R_orig\n",
    "    \n",
    "    # ==============================\n",
    "    # 2. 新增步骤：围绕 X 轴旋转 45 度 (向 -Y 方向)\n",
    "    # ==============================\n",
    "    print(\"🔧 增加旋转: 绕 X 轴旋转 45 度...\")\n",
    "\n",
    "    # 角度定义 (如果不确定方向，就把 -45 改成 45)\n",
    "    theta = np.radians(-45) \n",
    "    \n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    \n",
    "    # 绕 X 轴旋转矩阵 (Rotation around X-axis)\n",
    "    rot_x_mat = np.array([\n",
    "        [1, 0,  0],\n",
    "        [0, c, -s],\n",
    "        [0, s,  c]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # 左乘：在当前坐标系(Camera Frame)下应用旋转\n",
    "    R_final = rot_x_mat @ R_mirrored\n",
    "    \n",
    "    # ==============================\n",
    "    # 3. 组装最终矩阵\n",
    "    # ==============================\n",
    "    T_final = np.eye(4)\n",
    "    T_final[:3, :3] = R_final\n",
    "    T_final[:3, 3] = t_orig # 保持平移不变\n",
    "    \n",
    "    # B. 机器人：底座系 mesh 用 base_to_cam 变换到相机系\n",
    "    base_to_cam = robot_data.base_to_cam\n",
    "    for item in meshes_data:\n",
    "        mesh_o3d = item['mesh']\n",
    "        verts = np.asarray(mesh_o3d.vertices)\n",
    "        faces = np.asarray(mesh_o3d.triangles)\n",
    "        verts_h = np.hstack([verts, np.ones((len(verts), 1))])\n",
    "\n",
    "        verts_cam = (base_to_cam @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        # # 使用修改后的矩阵 base_to_cam_no_rot\n",
    "        # verts_cam = (base_to_cam_no_rot @ verts_h.T).T[:, :3]\n",
    "\n",
    "        # ---> 这里改成 T_final <---\n",
    "        verts_cam = (T_final @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        mesh_plt = k3d.mesh(\n",
    "            vertices=verts_cam.astype(np.float32),\n",
    "            indices=faces.astype(np.uint32),\n",
    "            color=0xff0000, # 红色\n",
    "            opacity=0.7,    # 半透明，方便看重合度\n",
    "            name=item['link_name']\n",
    "        )\n",
    "        plot += mesh_plt\n",
    "\n",
    "    # C. 坐标轴：相机系原点 (红X 绿Y 蓝Z)\n",
    "    plot += k3d.line([[0,0,0], [0.2,0,0]], color=0xff0000, width=0.01)\n",
    "    plot += k3d.line([[0,0,0], [0,0.2,0]], color=0x00ff00, width=0.01)\n",
    "    plot += k3d.line([[0,0,0], [0,0,0.2]], color=0x0000ff, width=0.01)\n",
    "    plot += k3d.points([[0,0,0]], color=0xffff00, point_size=0.03)\n",
    "    \n",
    "    plot.display()\n",
    "    print(\"✅ 完成。点云与机器人均在相机坐标系下；红色为 FK 机器人（经 base_to_cam 映射到相机系）。\")\n",
    "\n",
    "# ==============================\n",
    "# 运行调试\n",
    "# ==============================\n",
    "# 请确保路径正确\n",
    "rgb_path = \"/data/haoxiang/data/FLIPPING_v3/train/scene_0001/cam_104122060902/color/1767593840262.png\"\n",
    "depth_path = \"/data/haoxiang/data/FLIPPING_v3/train/scene_0001/cam_104122060902/depth/1767593840262.png\"\n",
    "\n",
    "target_idx = 0\n",
    "debug_alignment_k3d(robot_data, target_idx, rgb_path, depth_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用 RobotRenderer 类 (高级用法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 AirExo-2 的 RobotRenderer 类进行渲染\n",
    "# 注意:这需要双臂配置,但我们可以适配为单臂\n",
    "\n",
    "print(\"\\n🎬 使用 RobotRenderer 类渲染...\")\n",
    "\n",
    "# 创建一个虚拟的右臂配置 (全零)\n",
    "class DummyJointConfig:\n",
    "    def __init__(self):\n",
    "        self.num_joints = 8\n",
    "        self.num_robot_joints = 7\n",
    "\n",
    "renderer = RobotRenderer(\n",
    "    # left_joint_cfgs=DummyJointConfig(), # 虚拟左臂\n",
    "    # right_joint_cfgs=robot_data.joint_cfgs,  \n",
    "    left_joint_cfgs = robot_data.joint_cfgs, \n",
    "    right_joint_cfgs = DummyJointConfig(),\n",
    "    cam_to_base=robot_data.cam_to_base,\n",
    "    intrinsic=robot_data.intrinsic,\n",
    "    width=1280,\n",
    "    height=720,\n",
    "    near_plane=0.01,\n",
    "    far_plane=100.0,\n",
    "    # urdf_file=os.path.join(AIREXO_PATH, \"airexo/urdf_models/robot/robot.urdf\")\n",
    "    urdf_file=\"airexo/urdf_models/robot/robot.urdf\"\n",
    ")\n",
    "\n",
    "# 更新关节状态\n",
    "# right_joint = robot_data.get_joint_at_timestamp(FRAME_IDX)\n",
    "# left_joint = np.zeros(8)  # 虚拟左臂\n",
    "right_joint = np.zeros(8)\n",
    "left_joint = robot_data.get_joint_at_timestamp(FRAME_IDX)\n",
    "\n",
    "\n",
    "renderer.update_joints(left_joint, right_joint)\n",
    "\n",
    "# 渲染\n",
    "rendered_image = renderer.render_image()\n",
    "rendered_depth = renderer.render_depth()\n",
    "\n",
    "# 显示\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rendered_image)\n",
    "plt.title(\"RobotRenderer - RGB\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "depth_vis = (rendered_depth / rendered_depth.max() * 255).astype(np.uint8)\n",
    "plt.imshow(depth_vis, cmap='jet')\n",
    "plt.title(\"RobotRenderer - Depth\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ RobotRenderer 渲染完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 批量处理多帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_render_frames(robot_data, frame_indices, output_dir=\"./batch_output\"):\n",
    "    \"\"\"\n",
    "    批量渲染多帧\n",
    "    \n",
    "    参数:\n",
    "        robot_data: 数据加载器\n",
    "        frame_indices: 要渲染的帧索引列表\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\n📹 批量渲染 {len(frame_indices)} 帧...\")\n",
    "    \n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        print(f\"\\n[{i+1}/{len(frame_indices)}] 处理帧 {frame_idx}\")\n",
    "        \n",
    "        # 重建\n",
    "        _, _, meshes = reconstruct_robot_at_frame(robot_data, frame_idx)\n",
    "        \n",
    "        # 渲染\n",
    "        rgb, depth = render_robot_image(robot_data, meshes)\n",
    "        \n",
    "        # 保存\n",
    "        output_path = os.path.join(output_dir, f\"frame_{frame_idx:06d}.png\")\n",
    "        Image.fromarray(rgb).save(output_path)\n",
    "        print(f\"  ✓ 已保存: {output_path}\")\n",
    "    \n",
    "    print(f\"\\n✓ 批量渲染完成! 输出目录: {output_dir}\")\n",
    "\n",
    "\n",
    "# 示例: 渲染第 0, 100, 200, 300, 400 帧\n",
    "batch_render_frames(\n",
    "    robot_data,\n",
    "    frame_indices=[0, 100, 200, 300, 400],\n",
    "    output_dir=\"./reconstruction_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 导出完整 3D 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_3d_model(meshes, output_path=\"robot_model.ply\"):\n",
    "    \"\"\"\n",
    "    导出合并后的 3D 模型\n",
    "    \n",
    "    参数:\n",
    "        meshes: 网格列表\n",
    "        output_path: 输出文件路径\n",
    "    \"\"\"\n",
    "    print(f\"\\n💾 导出 3D 模型...\")\n",
    "    \n",
    "    # 合并所有网格\n",
    "    combined_mesh = o3d.geometry.TriangleMesh()\n",
    "    for mesh_data in meshes:\n",
    "        combined_mesh += mesh_data['mesh']\n",
    "    \n",
    "    # 重新计算法线\n",
    "    combined_mesh.compute_vertex_normals()\n",
    "    \n",
    "    # 保存\n",
    "    o3d.io.write_triangle_mesh(output_path, combined_mesh)\n",
    "    \n",
    "    print(f\"✓ 3D 模型已保存: {output_path}\")\n",
    "    print(f\"  - 顶点数: {len(combined_mesh.vertices)}\")\n",
    "    print(f\"  - 三角形数: {len(combined_mesh.triangles)}\")\n",
    "\n",
    "\n",
    "# 导出第 100 帧的 3D 模型\n",
    "export_3d_model(meshes, output_path=f\"robot_frame_{FRAME_IDX}.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本 Notebook 展示了如何使用 AirExo-2 的原生函数从 lowdim 数据重建单臂机器人的 3D 模型:\n",
    "\n",
    "1. ✅ **数据加载**: 从 HDF5 文件读取关节角度和标定数据\n",
    "2. ✅ **正向运动学**: 使用 `forward_kinematic_single` 计算 link 变换\n",
    "3. ✅ **3D 重建**: 加载 URDF 网格并应用变换\n",
    "4. ✅ **可视化**: 使用 Open3D 进行交互式 3D 可视化\n",
    "5. ✅ **渲染**: 使用离屏渲染器生成 RGB 和深度图\n",
    "6. ✅ **批量处理**: 支持多帧批量渲染\n",
    "7. ✅ **模型导出**: 导出 PLY 格式的 3D 模型\n",
    "\n",
    "### 关键技术点\n",
    "\n",
    "- **标定**: pose_in_link 为 7 维 (xyz+四元数)，表示相机在机械臂 base 下的位姿；cam_to_base 为相机系→底座系，base_to_cam 为其逆。\n",
    "- **渲染/对齐**: mesh 在底座系，经 base_to_cam 映射到相机系后与点云（相机系）一致；渲染时变换链为 base_to_cam → O3D_RENDER_TRANSFORMATION。\n",
    "- **关节数据**: 7个机器人关节 (弧度) + 1个夹爪宽度\n",
    "- **URDF 解析**: 使用 `kinpy` 库进行正向运动学\n",
    "- **渲染管线**: Open3D 离屏渲染 + 相机内参投影\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 🎥 制作动画序列\n",
    "- 🔄 与真实 RGB 图像叠加对比\n",
    "- 📊 分析 TCP 位姿误差\n",
    "- 🎮 集成到数据可视化工具"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airexo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
