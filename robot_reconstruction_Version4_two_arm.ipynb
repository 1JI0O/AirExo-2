{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双臂机器人 3D 重建 (基于 AirExo-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# # 添加 AirExo-2 到 Python 路径\n",
    "# AIREXO_PATH = \"/path/to/AirExo-2\"  # 修改为你的 AirExo-2 路径\n",
    "# sys.path.insert(0, AIREXO_PATH)\n",
    "\n",
    "# 导入 AirExo-2 模块\n",
    "from airexo.helpers.urdf_robot import forward_kinematic_single\n",
    "from airexo.helpers.constants import (\n",
    "    ROBOT_PREDEFINED_TRANSFORMATION, \n",
    "    O3D_RENDER_TRANSFORMATION,\n",
    "    ROBOT_LEFT_CAM_TO_TCP,   # ✅ 添加左臂\n",
    "    ROBOT_RIGHT_CAM_TO_TCP   # ✅ 添加右臂\n",
    ")\n",
    "from airexo.helpers.renderer import RobotRenderer\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "print(\"✓ 所有库导入成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "'type': 'robot', \n",
    "'camera_serials': ['105422061350', '104122064161', '104122061330'], \n",
    "'camera_serials_global': ['105422061350'], 'camera_serial_inhand_left': '104122064161', \n",
    "'camera_serial_inhand_right': '104122061330', \n",
    "'intrinsics': {\n",
    "    '105422061350': array([[912.4466 ,   0.     , 633.4127 ],\n",
    "       [  0.     , 911.4704 , 364.21265],\n",
    "       [  0.     ,   0.     ,   1.     ]], dtype=float32), \n",
    "    '104122064161': array([[915.71423,   0.     , 638.86804],\n",
    "       [  0.     , 915.29736, 357.55472],\n",
    "       [  0.     ,   0.     ,   1.     ]], dtype=float32), \n",
    "    '104122061330': array([[909.9401 ,   0.     , 626.91187],\n",
    "       [  0.     , 909.0405 , 354.72583],\n",
    "       [  0.     ,   0.     ,   1.     ]], dtype=float32)}, \n",
    "'extrinsics': {\n",
    "    '105422061350': array([[-0.03884323, -0.99906784,  0.01883331,  0.01281536],\n",
    "       [-0.91665816,  0.02812369, -0.39868146,  0.024272  ],\n",
    "       [ 0.39778018, -0.03274978, -0.91689605,  0.68936044],\n",
    "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
    "      dtype=float32), \n",
    "    '104122064161': array([[-0.94874346, -0.25861034, -0.18167697,  0.07677209],\n",
    "       [-0.18934393,  0.9253561 , -0.32842812, -0.03099394],\n",
    "       [ 0.25305077, -0.2771946 , -0.9268918 ,  0.38643917],\n",
    "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
    "      dtype=float32), \n",
    "    '104122061330': array([[ 0.9448085 , -0.29227304,  0.14803174, -0.09153452],\n",
    "       [-0.2114339 , -0.8890973 , -0.4059578 , -0.0019359 ],\n",
    "       [ 0.25026512,  0.35225344, -0.9018231 ,  0.39790273],\n",
    "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
    "      dtype=float32)}, \n",
    "'robot_left': {'tcp_pose': array([ 0.47990388,  0.05316564,  0.39616618,  0.1864741 ,  0.5887938 ,\n",
    "        0.78571755, -0.0346007 ], dtype=float32), 'joint_pos': array([ 0.44278383, -1.0634778 ,  1.3928185 , -1.5582722 , -1.60449   ,\n",
    "       -0.49928525,  0.33921626], dtype=float32), 'tcp_vel': array([ 0.00069122,  0.00031965, -0.00019603, -0.00065898,  0.00021872,\n",
    "        0.00270903], dtype=float32), 'joint_vel': array([ 1.3076103e-03, -1.7766005e-03, -1.9677939e-04, -2.6353818e-04,\n",
    "        1.8236322e-03,  6.1336366e-05, -1.6573255e-03], dtype=float32), 'force_torque': array([-0.06381213, -1.8813924 ,  1.2751839 , -1.0001243 , -0.07868998,\n",
    "       -0.30840093], dtype=float32)}, 'robot_right': {'tcp_pose': array([ 0.5281115 , -0.00951796,  0.3995147 ,  0.18649498, -0.56400096,\n",
    "        0.8018281 ,  0.06476301], dtype=float32), 'joint_pos': array([ 0.38581365, -0.7189137 ,  1.9208367 , -1.4884975 , -1.9956506 ,\n",
    "       -0.03493906,  0.42234862], dtype=float32), 'tcp_vel': array([-1.3955230e-04,  1.0149263e-04,  2.2846512e-05,  4.6651743e-04,\n",
    "        3.4199504e-04, -7.8015501e-04], dtype=float32), 'joint_vel': array([-0.0002656 , -0.00160371,  0.00064964,  0.00167814, -0.00441418,\n",
    "        0.00349331, -0.00212246], dtype=float32), 'force_torque': array([ 4.2057753 ,  6.2080684 ,  4.4443674 ,  1.9914904 , -1.7823514 ,\n",
    "        0.84697425], dtype=float32)}}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 数据路径配置 =====\n",
    "SCENE_PATH = \"/data/haoxiang/data/FLIPPING_v3/train/scene_0001\"\n",
    "LOWDIM_H5_PATH = os.path.join(SCENE_PATH, \"lowdim/lowdim.h5\")\n",
    "CALIB_PATH = \"/data/haoxiang/data/airexo2/task_0013/calib/1737548651048.npy\"\n",
    "\n",
    "# ===== 标定数据 =====\n",
    "CALIB_RAW = np.load(CALIB_PATH, allow_pickle=True).item()\n",
    "\n",
    "# ===== 双臂 URDF 配置 =====\n",
    "URDF_FILE_LEFT = \"airexo/urdf_models/robot/left_robot_inhand.urdf\"\n",
    "URDF_FILE_RIGHT = \"airexo/urdf_models/robot/right_robot_inhand.urdf\"\n",
    "\n",
    "# ===== 双臂关节配置 =====\n",
    "JOINT_CFG_PATH_LEFT = \"airexo/configs/joint/left/robot.yaml\"\n",
    "JOINT_CFG_PATH_RIGHT = \"airexo/configs/joint/right/robot.yaml\"\n",
    "\n",
    "# # ===== 双臂 URDF 配置 =====\n",
    "# URDF_FILE_LEFT = \"airexo/urdf_models/robot/right_robot_inhand.urdf\"\n",
    "# URDF_FILE_RIGHT = \"airexo/urdf_models/robot/left_robot_inhand.urdf\"\n",
    "\n",
    "# # ===== 双臂关节配置 =====\n",
    "# JOINT_CFG_PATH_LEFT = \"airexo/configs/joint/left/robot.yaml\"\n",
    "# JOINT_CFG_PATH_RIGHT = \"airexo/configs/joint/right/robot.yaml\"\n",
    "\n",
    "\n",
    "print(\"✓ 配置加载成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 3: 加载数据和标定处理\n",
    "# ========================================\n",
    "\n",
    "class DualArmRobotData:\n",
    "    \"\"\"\n",
    "    双臂机器人数据加载器\n",
    "    负责加载 HDF5 数据和处理标定信息\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lowdim_h5_path, calib_raw, \n",
    "                 joint_cfg_left, joint_cfg_right, \n",
    "                 urdf_left, urdf_right):\n",
    "        self.lowdim_h5_path = lowdim_h5_path\n",
    "        self.calib_raw = calib_raw\n",
    "        \n",
    "        # 左臂配置\n",
    "        self.urdf_file_left = urdf_left\n",
    "        self.joint_cfgs_left = OmegaConf.load(joint_cfg_left)\n",
    "        \n",
    "        # 右臂配置\n",
    "        self.urdf_file_right = urdf_right\n",
    "        self.joint_cfgs_right = OmegaConf.load(joint_cfg_right)\n",
    "        \n",
    "        # 执行数据加载\n",
    "        self._load_lowdim_data()\n",
    "        self._process_calibration()\n",
    "    \n",
    "    def _load_lowdim_data(self):\n",
    "        \"\"\"从 HDF5 文件加载 lowdim 数据\"\"\"\n",
    "        print(f\"\\n[INFO] 加载 lowdim 数据: {self.lowdim_h5_path}\")\n",
    "        \n",
    "        with h5py.File(self.lowdim_h5_path, 'r') as f:\n",
    "            self.timestamps = f['timestamp'][:]\n",
    "            \n",
    "            # 从标定数据中获取相机序列号\n",
    "            self.cam_serial_left = self.calib_raw['camera_serial_inhand_left']\n",
    "            self.cam_serial_right = self.calib_raw['camera_serial_inhand_right']\n",
    "            self.cam_serial_global = self.calib_raw['camera_serials_global'][0]\n",
    "            \n",
    "            print(f\"[INFO] 左臂相机: {self.cam_serial_left}\")\n",
    "            print(f\"[INFO] 右臂相机: {self.cam_serial_right}\")\n",
    "            print(f\"[INFO] 全局相机: {self.cam_serial_global}\")\n",
    "            print(f\"[INFO] 总帧数: {len(self.timestamps)}\")\n",
    "    \n",
    "    def _process_calibration(self):\n",
    "        \"\"\"\n",
    "        处理标定数据,计算全局相机到机器人底座的变换\n",
    "        \n",
    "        变换链(以左臂为例):\n",
    "        GlobalCam -> Marker -> InhandCam -> TCP -> Base(Real) -> Base(URDF)\n",
    "        \"\"\"\n",
    "        print(f\"\\n[INFO] 处理标定数据...\")\n",
    "        \n",
    "        # -------------------- 1. 内参 --------------------\n",
    "        intrinsics = self.calib_raw['intrinsics']\n",
    "        self.intrinsic_global = intrinsics[self.cam_serial_global]\n",
    "        self.intrinsic_left = intrinsics[self.cam_serial_left]\n",
    "        self.intrinsic_right = intrinsics[self.cam_serial_right]\n",
    "        \n",
    "        # -------------------- 2. 外参 --------------------\n",
    "        extrinsics = self.calib_raw['extrinsics']\n",
    "        \n",
    "        # -------------------- 3. 左臂变换链 --------------------\n",
    "        robot_left = self.calib_raw['robot_left']\n",
    "        \n",
    "        # 注意: 经过测试验证,tcp_pose 在你的数据中是 TCP->Base (不是 Base->TCP)\n",
    "        # 所以直接使用,不需要求逆\n",
    "        T_tcp_to_base_left = self._pose7d_to_matrix(robot_left['tcp_pose'])\n",
    "        \n",
    "        # 完整变换链:\n",
    "        # camera_to_robot_left = \n",
    "        #   extrinsics[global]           : GlobalCam -> Marker\n",
    "        #   @ inv(extrinsics[left])      : Marker -> LeftInhandCam\n",
    "        #   @ ROBOT_LEFT_CAM_TO_TCP      : LeftInhandCam -> TCP\n",
    "        #   @ T_tcp_to_base_left         : TCP -> Base(Real)\n",
    "        #   @ inv(ROBOT_PREDEFINED_TRANSFORMATION) : Base(Real) -> Base(URDF)\n",
    "        \n",
    "        camera_to_robot_left = \\\n",
    "            extrinsics[self.cam_serial_global] @ \\\n",
    "            np.linalg.inv(extrinsics[self.cam_serial_left]) @ \\\n",
    "            ROBOT_LEFT_CAM_TO_TCP @ \\\n",
    "            T_tcp_to_base_left @ \\\n",
    "            np.linalg.inv(ROBOT_PREDEFINED_TRANSFORMATION)\n",
    "        \n",
    "        # -------------------- 4. 右臂变换链 --------------------\n",
    "        robot_right = self.calib_raw['robot_right']\n",
    "        T_tcp_to_base_right = self._pose7d_to_matrix(robot_right['tcp_pose'])\n",
    "        \n",
    "        camera_to_robot_right = \\\n",
    "            extrinsics[self.cam_serial_global] @ \\\n",
    "            np.linalg.inv(extrinsics[self.cam_serial_right]) @ \\\n",
    "            ROBOT_RIGHT_CAM_TO_TCP @ \\\n",
    "            T_tcp_to_base_right @ \\\n",
    "            np.linalg.inv(ROBOT_PREDEFINED_TRANSFORMATION)\n",
    "        \n",
    "        # -------------------- 5. 存储结果 --------------------\n",
    "        # camera_to_robot: 从全局相机系到 URDF Base 系的变换\n",
    "        self.camera_to_robot_left = camera_to_robot_left.astype(np.float32)\n",
    "        self.camera_to_robot_right = camera_to_robot_right.astype(np.float32)\n",
    "        \n",
    "        # -------------------- 6. 验证输出 --------------------\n",
    "        print(f\"\\n[VERIFY] 左臂底座在全局相机系:\")\n",
    "        print(f\"  XYZ: {camera_to_robot_left[:3, 3]}\")\n",
    "        print(f\"  Z: {camera_to_robot_left[2, 3]:.3f} m\")\n",
    "        \n",
    "        print(f\"\\n[VERIFY] 右臂底座在全局相机系:\")\n",
    "        print(f\"  XYZ: {camera_to_robot_right[:3, 3]}\")\n",
    "        print(f\"  Z: {camera_to_robot_right[2, 3]:.3f} m\")\n",
    "        \n",
    "        print(f\"\\n[VERIFY] 标定板在全局相机系:\")\n",
    "        print(f\"  Z: {extrinsics[self.cam_serial_global][2, 3]:.3f} m\")\n",
    "        print(f\"  (底座 Z 应该 > 标定板 Z)\")\n",
    "    \n",
    "    def _pose7d_to_matrix(self, pose_7d):\n",
    "        \"\"\"\n",
    "        将 7D 位姿 (x, y, z, qx, qy, qz, qw) 转换为 4x4 齐次变换矩阵\n",
    "        \n",
    "        Args:\n",
    "            pose_7d: [x, y, z, q0, q1, q2, q3]\n",
    "        \n",
    "        Returns:\n",
    "            4x4 变换矩阵\n",
    "        \"\"\"\n",
    "        from scipy.spatial.transform import Rotation\n",
    "        \n",
    "        t = np.array(pose_7d[:3], dtype=np.float32)\n",
    "        quat = np.array(pose_7d[3:], dtype=np.float32)\n",
    "        \n",
    "        # 检测四元数格式: 如果第一个元素接近 1,可能是 [w,x,y,z] 格式\n",
    "        # scipy 需要 [x,y,z,w] 格式\n",
    "        if np.abs(quat[0]) > 0.9:\n",
    "            quat = [quat[1], quat[2], quat[3], quat[0]]\n",
    "        \n",
    "        R_mat = Rotation.from_quat(quat).as_matrix()\n",
    "        \n",
    "        T = np.eye(4, dtype=np.float32)\n",
    "        T[:3, :3] = R_mat\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "    \n",
    "    def get_robot_state_at_frame(self, frame_idx):\n",
    "        \"\"\"\n",
    "        获取指定帧的双臂关节状态\n",
    "        \n",
    "        注意: 当前实现假设标定文件中的 robot_left/right 是静态的\n",
    "        如果 lowdim.h5 中有每帧的关节角度,需要从那里读取\n",
    "        \n",
    "        Returns:\n",
    "            left_joint: 左臂关节状态 (7个关节 + 1个夹爪)\n",
    "            right_joint: 右臂关节状态 (7个关节 + 1个夹爪)\n",
    "        \"\"\"\n",
    "        robot_left = self.calib_raw.get('robot_left', None)\n",
    "        robot_right = self.calib_raw.get('robot_right', None)\n",
    "        \n",
    "        left_joint = None\n",
    "        right_joint = None\n",
    "        \n",
    "        if robot_left is not None:\n",
    "            joint_pos_left = robot_left['joint_pos']  # (7,)\n",
    "            ee_state_left = 0.0  # 夹爪状态,暂用 0\n",
    "            left_joint = np.concatenate([joint_pos_left, [ee_state_left]])\n",
    "        \n",
    "        if robot_right is not None:\n",
    "            joint_pos_right = robot_right['joint_pos']  # (7,)\n",
    "            ee_state_right = 0.0\n",
    "            right_joint = np.concatenate([joint_pos_right, [ee_state_right]])\n",
    "        \n",
    "        return left_joint, right_joint\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 创建数据加载器实例\n",
    "# ========================================\n",
    "robot_data = DualArmRobotData(\n",
    "    lowdim_h5_path=LOWDIM_H5_PATH,\n",
    "    calib_raw=CALIB_RAW,\n",
    "    joint_cfg_left=JOINT_CFG_PATH_LEFT,\n",
    "    joint_cfg_right=JOINT_CFG_PATH_RIGHT,\n",
    "    urdf_left=URDF_FILE_LEFT,\n",
    "    urdf_right=URDF_FILE_RIGHT\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 正向运动学重建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 4: FK 重建\n",
    "# ========================================\n",
    "\n",
    "def reconstruct_dual_arm_at_frame(robot_data, frame_idx):\n",
    "    \"\"\"\n",
    "    对指定帧执行双臂 FK 重建,生成 3D mesh\n",
    "    \n",
    "    变换链:\n",
    "    Mesh(local) -> Link(URDF Base) -> Real Base -> Camera\n",
    "    \n",
    "    参考: airexo/helpers/renderer.py L209\n",
    "    \n",
    "    Args:\n",
    "        robot_data: DualArmRobotData 实例\n",
    "        frame_idx: 帧索引\n",
    "    \n",
    "    Returns:\n",
    "        meshes_left: 左臂 mesh 列表\n",
    "        meshes_right: 右臂 mesh 列表\n",
    "    \"\"\"\n",
    "    print(f\"\\n[INFO] FK 重建 - 帧 {frame_idx}\")\n",
    "    \n",
    "    left_joint, right_joint = robot_data.get_robot_state_at_frame(frame_idx)\n",
    "    meshes_left = []\n",
    "    meshes_right = []\n",
    "    \n",
    "    # -------------------- 左臂 FK --------------------\n",
    "    if left_joint is not None:\n",
    "        transforms_left, visuals_left = forward_kinematic_single(\n",
    "            joint=left_joint,\n",
    "            joint_cfgs=robot_data.joint_cfgs_left,\n",
    "            is_rad=True,\n",
    "            urdf_file=robot_data.urdf_file_left,\n",
    "            with_visuals_map=True\n",
    "        )\n",
    "        \n",
    "        urdf_dir_left = os.path.dirname(robot_data.urdf_file_left)\n",
    "        \n",
    "        for link_name, transform in transforms_left.items():\n",
    "            for visual in visuals_left.get(link_name, []):\n",
    "                if visual.geom_param is None:\n",
    "                    continue\n",
    "                \n",
    "                # 获取 mesh 文件路径\n",
    "                mesh_file = visual.geom_param\n",
    "                if isinstance(mesh_file, (list, tuple)):\n",
    "                    mesh_file = mesh_file[0]\n",
    "                \n",
    "                mesh_path = os.path.join(urdf_dir_left, mesh_file)\n",
    "                if not os.path.exists(mesh_path):\n",
    "                    continue\n",
    "                \n",
    "                # 变换链 (参考官方 renderer.py):\n",
    "                # camera_to_robot @ ROBOT_PREDEFINED_TRANSFORMATION @ FK @ offset\n",
    "                # \n",
    "                # camera_to_robot: Camera -> URDF Base\n",
    "                # ROBOT_PREDEFINED_TRANSFORMATION: URDF Base -> Real Base\n",
    "                # transform: Real Base -> Link\n",
    "                # offset: Link -> Mesh\n",
    "                #\n",
    "                # 结果: Camera -> Mesh\n",
    "                \n",
    "                tf = robot_data.camera_to_robot_left @ \\\n",
    "                     ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     transform.matrix() @ \\\n",
    "                     visual.offset.matrix()\n",
    "                \n",
    "                # 加载并变换 mesh\n",
    "                mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "                mesh.transform(tf)\n",
    "                mesh.compute_vertex_normals()\n",
    "                mesh.paint_uniform_color([0.3, 0.6, 0.9])  # 蓝色\n",
    "                \n",
    "                meshes_left.append({\n",
    "                    'arm': 'left',\n",
    "                    'link_name': link_name,\n",
    "                    'mesh': mesh\n",
    "                })\n",
    "    \n",
    "    # -------------------- 右臂 FK --------------------\n",
    "    if right_joint is not None:\n",
    "        transforms_right, visuals_right = forward_kinematic_single(\n",
    "            joint=right_joint,\n",
    "            joint_cfgs=robot_data.joint_cfgs_right,\n",
    "            is_rad=True,\n",
    "            urdf_file=robot_data.urdf_file_right,\n",
    "            with_visuals_map=True\n",
    "        )\n",
    "        \n",
    "        urdf_dir_right = os.path.dirname(robot_data.urdf_file_right)\n",
    "        \n",
    "        for link_name, transform in transforms_right.items():\n",
    "            for visual in visuals_right.get(link_name, []):\n",
    "                if visual.geom_param is None:\n",
    "                    continue\n",
    "                \n",
    "                mesh_file = visual.geom_param\n",
    "                if isinstance(mesh_file, (list, tuple)):\n",
    "                    mesh_file = mesh_file[0]\n",
    "                \n",
    "                mesh_path = os.path.join(urdf_dir_right, mesh_file)\n",
    "                if not os.path.exists(mesh_path):\n",
    "                    continue\n",
    "                \n",
    "                tf = robot_data.camera_to_robot_right @ \\\n",
    "                     ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     transform.matrix() @ \\\n",
    "                     visual.offset.matrix()\n",
    "                \n",
    "                mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "                mesh.transform(tf)\n",
    "                mesh.compute_vertex_normals()\n",
    "                mesh.paint_uniform_color([0.9, 0.3, 0.3])  # 红色\n",
    "                \n",
    "                meshes_right.append({\n",
    "                    'arm': 'right',\n",
    "                    'link_name': link_name,\n",
    "                    'mesh': mesh\n",
    "                })\n",
    "    \n",
    "    print(f\"[INFO] 重建完成: 左臂 {len(meshes_left)} meshes, 右臂 {len(meshes_right)} meshes\")\n",
    "    return meshes_left, meshes_right\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 执行重建\n",
    "# ========================================\n",
    "FRAME_IDX = 0\n",
    "meshes_left, meshes_right = reconstruct_dual_arm_at_frame(robot_data, FRAME_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 3D 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 5: K3D 可视化 (简化版)\n",
    "# ========================================\n",
    "\n",
    "import k3d\n",
    "\n",
    "def visualize_dual_arm_k3d(meshes_left, meshes_right):\n",
    "    \"\"\"\n",
    "    使用 K3D 可视化双臂机器人\n",
    "    meshes 已经在全局相机坐标系下,直接显示\n",
    "    \"\"\"\n",
    "    plot = k3d.plot(\n",
    "        grid_visible=True,\n",
    "        background_color=0xffffff,\n",
    "        camera_auto_fit=True\n",
    "    )\n",
    "    \n",
    "    # 左臂 (蓝色)\n",
    "    for item in meshes_left:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        plot += k3d.mesh(verts, faces, color=0x4D96FF, opacity=0.8)\n",
    "    \n",
    "    # 右臂 (红色)\n",
    "    for item in meshes_right:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        plot += k3d.mesh(verts, faces, color=0xFF4D4D, opacity=0.8)\n",
    "    \n",
    "    # 坐标轴\n",
    "    axis_len = 0.2\n",
    "    plot += k3d.line([[0,0,0], [axis_len,0,0]], color=0xff0000, width=0.01)\n",
    "    plot += k3d.line([[0,0,0], [0,axis_len,0]], color=0x00ff00, width=0.01)\n",
    "    plot += k3d.line([[0,0,0], [0,0,axis_len]], color=0x0000ff, width=0.01)\n",
    "    \n",
    "    plot.display()\n",
    "    return plot\n",
    "\n",
    "plot_instance = visualize_dual_arm_k3d(meshes_left, meshes_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 点云对齐验证\n",
    "# ========================================\n",
    "\n",
    "import k3d\n",
    "import cv2\n",
    "\n",
    "def debug_dual_arm_alignment_k3d(robot_data, frame_idx, \n",
    "                                  rgb_path_global, depth_path_global,\n",
    "                                  subsample_step=4):\n",
    "    \"\"\"\n",
    "    将点云和机械臂 mesh 在同一坐标系下显示\n",
    "    \n",
    "    Args:\n",
    "        robot_data: DualArmRobotData 实例\n",
    "        frame_idx: 帧索引\n",
    "        rgb_path_global: 全局相机 RGB 图像路径\n",
    "        depth_path_global: 全局相机深度图路径\n",
    "        subsample_step: 点云降采样步长\n",
    "    \"\"\"\n",
    "    \n",
    "    # -------------------- 1. 生成点云 --------------------\n",
    "    print(\"\\n[INFO] 生成点云...\")\n",
    "    \n",
    "    color_img = cv2.cvtColor(cv2.imread(rgb_path_global), cv2.COLOR_BGR2RGB)\n",
    "    depth_img = cv2.imread(depth_path_global, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "    \n",
    "    # 内参\n",
    "    K = robot_data.intrinsic_global\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    \n",
    "    # 降采样\n",
    "    v_idx, u_idx = np.indices(depth_img.shape)\n",
    "    v_idx = v_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    u_idx = u_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    z = depth_img[::subsample_step, ::subsample_step].flatten()\n",
    "    colors = color_img[::subsample_step, ::subsample_step].reshape(-1, 3)\n",
    "    \n",
    "    # 过滤无效深度\n",
    "    valid_mask = (z > 0) & (z < 2000)  # 0-2000mm\n",
    "    u_idx = u_idx[valid_mask]\n",
    "    v_idx = v_idx[valid_mask]\n",
    "    z = z[valid_mask]\n",
    "    colors = colors[valid_mask]\n",
    "    \n",
    "    # 深度转米\n",
    "    z_m = z / 1000.0\n",
    "    \n",
    "    # 反投影到相机坐标系\n",
    "    x_m = (u_idx - cx) * z_m / fx\n",
    "    y_m = (v_idx - cy) * z_m / fy\n",
    "    points_cam = np.stack([x_m, y_m, z_m], axis=1)\n",
    "    \n",
    "    # 颜色转 K3D 格式\n",
    "    r = colors[:, 0].astype(np.uint32)\n",
    "    g = colors[:, 1].astype(np.uint32)\n",
    "    b = colors[:, 2].astype(np.uint32)\n",
    "    colors_int = (r << 16) | (g << 8) | b\n",
    "    \n",
    "    print(f\"[INFO] 点云范围:\")\n",
    "    print(f\"  X: [{points_cam[:, 0].min():.2f}, {points_cam[:, 0].max():.2f}]\")\n",
    "    print(f\"  Y: [{points_cam[:, 1].min():.2f}, {points_cam[:, 1].max():.2f}]\")\n",
    "    print(f\"  Z: [{points_cam[:, 2].min():.2f}, {points_cam[:, 2].max():.2f}]\")\n",
    "    \n",
    "    # -------------------- 2. FK 重建 --------------------\n",
    "    print(\"\\n[INFO] FK 重建...\")\n",
    "    meshes_left, meshes_right = reconstruct_dual_arm_at_frame(robot_data, frame_idx)\n",
    "    \n",
    "    # 提取所有 vertices 检查范围\n",
    "    all_verts_left = np.vstack([np.asarray(m['mesh'].vertices) for m in meshes_left])\n",
    "    all_verts_right = np.vstack([np.asarray(m['mesh'].vertices) for m in meshes_right])\n",
    "    \n",
    "    print(f\"\\n[INFO] 机械臂范围:\")\n",
    "    print(f\"  左臂 Z: [{all_verts_left[:, 2].min():.2f}, {all_verts_left[:, 2].max():.2f}]\")\n",
    "    print(f\"  右臂 Z: [{all_verts_right[:, 2].min():.2f}, {all_verts_right[:, 2].max():.2f}]\")\n",
    "    \n",
    "    # -------------------- 3. K3D 可视化 --------------------\n",
    "    print(\"\\n[INFO] 构建 K3D 场景...\")\n",
    "    plot = k3d.plot(\n",
    "        background_color=0xFFFFFF,\n",
    "        grid_visible=True,\n",
    "        camera_auto_fit=True\n",
    "    )\n",
    "    \n",
    "    # A. 点云\n",
    "    cloud_plt = k3d.points(\n",
    "        positions=points_cam.astype(np.float32),\n",
    "        colors=colors_int.astype(np.uint32),\n",
    "        point_size=0.004,\n",
    "        shader='flat',\n",
    "        name=\"Point Cloud\"\n",
    "    )\n",
    "    plot += cloud_plt\n",
    "    \n",
    "    # B. 左臂 (meshes 已在相机系)\n",
    "    for item in meshes_left:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        plot += k3d.mesh(verts, faces, color=0x4D96FF, opacity=0.8)\n",
    "    \n",
    "    # C. 右臂\n",
    "    for item in meshes_right:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        plot += k3d.mesh(verts, faces, color=0xFF4D4D, opacity=0.8)\n",
    "    \n",
    "    # D. 坐标轴\n",
    "    axis_len = 0.2\n",
    "    plot += k3d.line([[0,0,0], [axis_len,0,0]], color=0xff0000, width=0.015, name=\"X\")\n",
    "    plot += k3d.line([[0,0,0], [0,axis_len,0]], color=0x00ff00, width=0.015, name=\"Y\")\n",
    "    plot += k3d.line([[0,0,0], [0,0,axis_len]], color=0x0000ff, width=0.015, name=\"Z\")\n",
    "    plot += k3d.points([[0,0,0]], color=0xffff00, point_size=0.03, name=\"Camera Origin\")\n",
    "    \n",
    "    plot.display()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[SUCCESS] 完成!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"检查要点:\")\n",
    "    print(\"  1. 点云与 mesh 的 Z 范围是否接近\")\n",
    "    print(\"  2. 左右臂是否在点云的正确位置\")\n",
    "    print(\"  3. 夹爪与物体的位置关系\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 执行点云对齐\n",
    "# ========================================\n",
    "rgb_path_global = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001/cam_105422061350/color/1737546126606.png\"\n",
    "depth_path_global = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001/cam_105422061350/depth/1737546126606.png\"\n",
    "\n",
    "target_idx = 0\n",
    "debug_dual_arm_alignment_k3d(\n",
    "    robot_data, \n",
    "    target_idx, \n",
    "    rgb_path_global, \n",
    "    depth_path_global,\n",
    "    subsample_step=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用 FLIPPING_v3 的标定数据，通过 world-base 变换矩阵转换为 AirExo-2 坐标系\n",
    "实现点云对齐可视化\n",
    "\n",
    "FLIPPING_v3 的 pose_in_link 是 T_world_cam (world → camera)\n",
    "通过 T_world_base 转换为 T_cam_base (camera → robot_base)\n",
    "然后使用 AirExo-2 的渲染逻辑进行对齐\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import k3d\n",
    "import trimesh\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from airexo.helpers.urdf_robot import forward_kinematic\n",
    "from airexo.helpers.constants import ROBOT_PREDEFINED_TRANSFORMATION, O3D_RENDER_TRANSFORMATION\n",
    "import open3d as o3d\n",
    "\n",
    "# ========== 1. 定义变换矩阵 ==========\n",
    "\n",
    "# FLIPPING_v3 的 pose_in_link (T_world_cam, wxyz 格式)\n",
    "pose_in_link = np.array([\n",
    "    0.07783932332093665,\n",
    "    0.2078814260418823,\n",
    "    0.34723683952957585,\n",
    "    0.2273133855008057,\n",
    "    -0.6785647482083789,\n",
    "    0.6637673415778982,\n",
    "    -0.21746591345696367\n",
    "])\n",
    "\n",
    "# 四元数转旋转矩阵 (wxyz 格式)\n",
    "def quat_to_mat_wxyz(q):\n",
    "    w, x, y, z = q\n",
    "    return np.array([\n",
    "        [1 - 2*y*y - 2*z*z,     2*x*y - 2*z*w,     2*x*z + 2*y*w],\n",
    "        [    2*x*y + 2*z*w, 1 - 2*x*x - 2*z*z,     2*y*z - 2*x*w],\n",
    "        [    2*x*z - 2*y*w,     2*y*z + 2*x*w, 1 - 2*x*x - 2*y*y]\n",
    "    ])\n",
    "\n",
    "# 7D pose转4x4矩阵 (wxyz 格式)\n",
    "def pose7d_to_T_wxyz(pose7d):\n",
    "    xyz = pose7d[:3]\n",
    "    q = pose7d[3:]\n",
    "    R = quat_to_mat_wxyz(q)\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = xyz\n",
    "    return T\n",
    "\n",
    "# 转换为 T_world_cam\n",
    "T_world_cam = pose7d_to_T_wxyz(pose_in_link)\n",
    "T_cam_world = np.linalg.inv(T_world_cam)\n",
    "\n",
    "# world → robot_base 变换矩阵 (从 find_world_base_transform.py 计算得到)\n",
    "T_world_base_urdf = np.array([\n",
    "    [ 0.70771504, -0.6363821,  -0.30685198,  0.78460977],\n",
    "    [-0.27343178, -0.64720033,  0.71159471,  0.32980268],\n",
    "    [-0.6514406,  -0.4197032,  -0.63204052,  0.66463799],\n",
    "    [ 0.,          0.,          0.,          1.        ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 计算 T_cam_base (camera → URDF base)\n",
    "# T_cam_base = T_cam_world @ T_world_base\n",
    "T_cam_base = T_cam_world @ T_world_base_urdf\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"坐标系转换\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"FLIPPING_v3 的 T_world_cam (world → camera):\")\n",
    "print(T_world_cam)\n",
    "print()\n",
    "print(\"T_world_base_urdf (world → URDF base):\")\n",
    "print(T_world_base_urdf)\n",
    "print()\n",
    "print(\"转换后的 T_cam_base (camera → URDF base):\")\n",
    "print(T_cam_base)\n",
    "print()\n",
    "\n",
    "# ========== 2. 读取关节数据 ==========\n",
    "\n",
    "scene_path = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001\"\n",
    "lowdim_path = os.path.join(scene_path, \"lowdim\")\n",
    "\n",
    "with h5py.File(f\"{lowdim_path}/robot_left.h5\", 'r') as f:\n",
    "    left_joint = f['joint_pos'][0]\n",
    "\n",
    "with h5py.File(f\"{lowdim_path}/robot_right.h5\", 'r') as f:\n",
    "    right_joint = f['joint_pos'][0]\n",
    "\n",
    "with h5py.File(f\"{lowdim_path}/gripper_left.h5\", 'r') as f:\n",
    "    left_gripper = f['width'][0] if 'width' in f else 0.05\n",
    "\n",
    "with h5py.File(f\"{lowdim_path}/gripper_right.h5\", 'r') as f:\n",
    "    right_gripper = f['width'][0] if 'width' in f else 0.05\n",
    "\n",
    "left_joint = np.concatenate([left_joint, [left_gripper]])\n",
    "right_joint = np.concatenate([right_joint, [right_gripper]])\n",
    "\n",
    "print(f\"左臂关节: {left_joint}\")\n",
    "print(f\"右臂关节: {right_joint}\")\n",
    "print()\n",
    "\n",
    "# ========== 3. 前向运动学 ==========\n",
    "\n",
    "left_cfg = OmegaConf.load(\"airexo/configs/joint/left/robot.yaml\")\n",
    "right_cfg = OmegaConf.load(\"airexo/configs/joint/right/robot.yaml\")\n",
    "\n",
    "cur_transforms, visuals_map = forward_kinematic(\n",
    "    left_joint=left_joint,\n",
    "    right_joint=right_joint,\n",
    "    left_joint_cfgs=left_cfg,\n",
    "    right_joint_cfgs=right_cfg,\n",
    "    is_rad=True,\n",
    "    urdf_file=\"airexo/urdf_models/robot/robot_inhand.urdf\",\n",
    "    with_visuals_map=True\n",
    ")\n",
    "\n",
    "# ========== 4. 读取深度图并转换为点云 ==========\n",
    "\n",
    "# 使用相机序列号 105422061350\n",
    "camera_serial = \"105422061350\"\n",
    "cam_path = os.path.join(scene_path, f\"cam_{camera_serial}\")\n",
    "depth_path = os.path.join(cam_path, \"depth\", \"1737546126606.png\")\n",
    "rgb_path = os.path.join(cam_path, \"color\", \"1737546126606.png\")\n",
    "\n",
    "depth_img = o3d.io.read_image(depth_path)\n",
    "rgb_img = o3d.io.read_image(rgb_path)\n",
    "\n",
    "rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    rgb_img, depth_img,\n",
    "    depth_scale=1000.0,\n",
    "    convert_rgb_to_intensity=False\n",
    ")\n",
    "\n",
    "# 使用 AirExo-2 的内参\n",
    "intrinsic = np.array([\n",
    "    [912.4466, 0.0, 633.4127],\n",
    "    [0.0, 911.4704, 364.21265],\n",
    "    [0.0, 0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "fx = intrinsic[0, 0]\n",
    "fy = intrinsic[1, 1]\n",
    "cx = intrinsic[0, 2]\n",
    "cy = intrinsic[1, 2]\n",
    "h, w = np.asarray(rgb_img).shape[:2]\n",
    "\n",
    "intrinsic_o3d = o3d.camera.PinholeCameraIntrinsic(\n",
    "    width=int(w), height=int(h),\n",
    "    fx=float(fx), fy=float(fy),\n",
    "    cx=float(cx), cy=float(cy)\n",
    ")\n",
    "\n",
    "pcd_cam = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic_o3d)\n",
    "\n",
    "# ========== 5. K3D 可视化 ==========\n",
    "\n",
    "plot = k3d.plot()\n",
    "\n",
    "# 5.1 渲染机械臂\n",
    "# 使用转换后的 T_cam_base 进行渲染\n",
    "for link, transform in cur_transforms.items():\n",
    "    if link not in visuals_map: continue\n",
    "    \n",
    "    for v in visuals_map[link]:\n",
    "        if v.geom_param is None: continue\n",
    "        \n",
    "        mesh_path = os.path.join(\"airexo/urdf_models/robot\", v.geom_param)\n",
    "        if not os.path.exists(mesh_path):\n",
    "            continue\n",
    "\n",
    "        mesh = trimesh.load(mesh_path, force='mesh')\n",
    "        \n",
    "        # 使用转换后的 T_cam_base\n",
    "        # 变换链: mesh → link → URDF基座 → 相机坐标系 → Open3D渲染空间\n",
    "        tf = O3D_RENDER_TRANSFORMATION @ T_cam_base @ ROBOT_PREDEFINED_TRANSFORMATION @ transform.matrix() @ v.offset.matrix()\n",
    "        mesh.apply_transform(tf)\n",
    "        \n",
    "        plot += k3d.mesh(mesh.vertices.astype(np.float32), \n",
    "                         mesh.faces.astype(np.uint32),\n",
    "                         color=0xaaaaaa)\n",
    "\n",
    "# 5.2 渲染点云\n",
    "pcd_cam.transform(O3D_RENDER_TRANSFORMATION)\n",
    "\n",
    "pcd_points = np.asarray(pcd_cam.points).astype(np.float32)\n",
    "pcd_colors = np.asarray(pcd_cam.colors).astype(np.float32)\n",
    "pcd_colors_uint32 = (pcd_colors * 255).astype(np.uint32)\n",
    "pcd_colors_packed = (pcd_colors_uint32[:, 0] << 16) | \\\n",
    "                    (pcd_colors_uint32[:, 1] << 8) | \\\n",
    "                     pcd_colors_uint32[:, 2]\n",
    "\n",
    "plot += k3d.points(pcd_points, \n",
    "                   colors=pcd_colors_packed,\n",
    "                   point_size=0.002,\n",
    "                   shader='flat')\n",
    "\n",
    "# 5.3 添加坐标轴\n",
    "axis_size = 0.3\n",
    "axes = k3d.vectors(\n",
    "    origins=[[0, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "    vectors=[[axis_size, 0, 0], [0, axis_size, 0], [0, 0, axis_size]],\n",
    "    colors=[0xff0000, 0x00ff00, 0x0000ff],\n",
    "    line_width=0.01\n",
    ")\n",
    "plot += axes\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"可视化说明\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"1. 使用 FLIPPING_v3 的 pose_in_link (T_world_cam)\")\n",
    "print(\"2. 通过 T_world_base_urdf 转换为 T_cam_base (AirExo-2 坐标系)\")\n",
    "print(\"3. 使用 AirExo-2 的渲染逻辑进行点云对齐\")\n",
    "print()\n",
    "print(\"变换链:\")\n",
    "print(\"  机械臂: mesh → link → URDF基座 → 相机坐标系 → Open3D渲染空间\")\n",
    "print(\"  点云: 相机坐标系 → Open3D渲染空间\")\n",
    "print()\n",
    "print(\"关键变换:\")\n",
    "print(\"  T_cam_base = T_cam_world @ T_world_base_urdf\")\n",
    "print(\"  机械臂变换 = O3D_RENDER_TRANSFORMATION @ T_cam_base @ ROBOT_PREDEFINED_TRANSFORMATION @ transform @ offset\")\n",
    "print(\"  点云变换 = O3D_RENDER_TRANSFORMATION\")\n",
    "print()\n",
    "\n",
    "plot.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 诊断 Cell: 检查双臂底座位置关系\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n[DIAGNOSE] 双臂底座位置分析\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. 底座位置\n",
    "left_base_pos = robot_data.camera_to_robot_left[:3, 3]\n",
    "right_base_pos = robot_data.camera_to_robot_right[:3, 3]\n",
    "\n",
    "print(f\"左臂底座: {left_base_pos}\")\n",
    "print(f\"右臂底座: {right_base_pos}\")\n",
    "\n",
    "# 2. 双臂间距\n",
    "distance = np.linalg.norm(left_base_pos - right_base_pos)\n",
    "print(f\"\\n双臂底座间距: {distance:.3f} m\")\n",
    "\n",
    "# 3. 双臂相对方向\n",
    "relative_vec = right_base_pos - left_base_pos\n",
    "print(f\"左臂→右臂方向: {relative_vec}\")\n",
    "print(f\"  主要在 {'X' if abs(relative_vec[0]) > abs(relative_vec[1]) else 'Y'} 轴\")\n",
    "\n",
    "# 4. 底座朝向（通过旋转矩阵的 Z 轴判断）\n",
    "left_z_axis = robot_data.camera_to_robot_left[:3, 2]\n",
    "right_z_axis = robot_data.camera_to_robot_right[:3, 2]\n",
    "\n",
    "print(f\"\\n左臂底座 Z 轴方向: {left_z_axis}\")\n",
    "print(f\"右臂底座 Z 轴方向: {right_z_axis}\")\n",
    "\n",
    "# 5. 检查是否朝向中心\n",
    "center = (left_base_pos + right_base_pos) / 2\n",
    "left_to_center = center - left_base_pos\n",
    "right_to_center = center - right_base_pos\n",
    "\n",
    "# 底座的 X 轴应该指向对方（如果是面对面）\n",
    "left_x_axis = robot_data.camera_to_robot_left[:3, 0]\n",
    "right_x_axis = robot_data.camera_to_robot_right[:3, 0]\n",
    "\n",
    "left_facing_center = np.dot(left_x_axis, left_to_center) > 0\n",
    "right_facing_center = np.dot(right_x_axis, right_to_center) > 0\n",
    "\n",
    "print(f\"\\n左臂是否朝向中心: {left_facing_center}\")\n",
    "print(f\"右臂是否朝向中心: {right_facing_center}\")\n",
    "\n",
    "# 6. 参考：AirExo-2 论文中的双臂配置\n",
    "print(\"\\n[REFERENCE] AirExo-2 标准配置:\")\n",
    "print(\"  - 双臂底座间距: ~0.27m (ROBOT_REAL_BASE_TO_INDIVIDUAL_REAL_BASE * 2 = 0.135*2)\")\n",
    "print(\"  - 双臂应该面对面，朝向工作空间中心\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 7. 可能的���正方案\n",
    "print(\"\\n[SUGGESTION] 可能的问题和修正方案:\")\n",
    "\n",
    "if distance > 0.5:\n",
    "    print(\"  1. 间距过大 -> 可能左右臂标定数据弄反了\")\n",
    "    print(\"     建议交换 camera_to_robot_left 和 camera_to_robot_right\")\n",
    "\n",
    "if not (left_facing_center and right_facing_center):\n",
    "    print(\"  2. 朝向错误 -> 可能需要镜像变换\")\n",
    "    print(\"     或者 URDF 文件用错了（left用了right的，vice versa）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 4 完整修正版: 完全按照官方双臂 renderer\n",
    "# ========================================\n",
    "\n",
    "from airexo.helpers.constants import (\n",
    "    ROBOT_PREDEFINED_TRANSFORMATION,\n",
    "    LEFT_ROBOT_PREDEFINED_TRANSFORMATION,   # 新增\n",
    "    RIGHT_ROBOT_PREDEFINED_TRANSFORMATION,  # 新增\n",
    "    O3D_RENDER_TRANSFORMATION\n",
    ")\n",
    "\n",
    "def reconstruct_dual_arm_at_frame_official(robot_data, frame_idx):\n",
    "    \"\"\"\n",
    "    完全按照官方 RobotRenderer 双臂逻辑重建\n",
    "    \n",
    "    参考:\n",
    "    - airexo/helpers/renderer.py L334 (左臂)\n",
    "    - airexo/helpers/renderer.py L349 (右臂)\n",
    "    \n",
    "    关键区别:\n",
    "    - 单臂: cam_to_base @ ROBOT_PREDEFINED_TRANSFORMATION\n",
    "    - 双臂左: cam_to_left_base @ ROBOT_PREDEFINED_TRANSFORMATION @ LEFT_ROBOT_PREDEFINED_TRANSFORMATION\n",
    "    - 双臂右: cam_to_right_base @ ROBOT_PREDEFINED_TRANSFORMATION @ RIGHT_ROBOT_PREDEFINED_TRANSFORMATION\n",
    "    \"\"\"\n",
    "    print(f\"\\n[INFO] 官方逻辑 FK 重建 - 帧 {frame_idx}\")\n",
    "    \n",
    "    left_joint, right_joint = robot_data.get_robot_state_at_frame(frame_idx)\n",
    "    meshes_left = []\n",
    "    meshes_right = []\n",
    "    \n",
    "    # -------------------- 左臂 FK --------------------\n",
    "    if left_joint is not None:\n",
    "        transforms_left, visuals_left = forward_kinematic_single(\n",
    "            joint=left_joint,\n",
    "            joint_cfgs=robot_data.joint_cfgs_left,\n",
    "            is_rad=True,\n",
    "            urdf_file=robot_data.urdf_file_left,\n",
    "            with_visuals_map=True\n",
    "        )\n",
    "        \n",
    "        urdf_dir_left = os.path.dirname(robot_data.urdf_file_left)\n",
    "        \n",
    "        for link_name, transform in transforms_left.items():\n",
    "            for visual in visuals_left.get(link_name, []):\n",
    "                if visual.geom_param is None:\n",
    "                    continue\n",
    "                \n",
    "                mesh_file = visual.geom_param\n",
    "                if isinstance(mesh_file, (list, tuple)):\n",
    "                    mesh_file = mesh_file[0]\n",
    "                \n",
    "                mesh_path = os.path.join(urdf_dir_left, mesh_file)\n",
    "                if not os.path.exists(mesh_path):\n",
    "                    continue\n",
    "                \n",
    "                # 官方双臂左臂变换链 (renderer.py L334-337)\n",
    "                tf = O3D_RENDER_TRANSFORMATION @ \\\n",
    "                     robot_data.camera_to_robot_left @ \\\n",
    "                     ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     LEFT_ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     transform.matrix() @ \\\n",
    "                     visual.offset.matrix()\n",
    "                \n",
    "                mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "                mesh.transform(tf)\n",
    "                mesh.compute_vertex_normals()\n",
    "                mesh.paint_uniform_color([0.3, 0.6, 0.9])\n",
    "                \n",
    "                meshes_left.append({\n",
    "                    'arm': 'left',\n",
    "                    'link_name': link_name,\n",
    "                    'mesh': mesh\n",
    "                })\n",
    "    \n",
    "    # -------------------- 右臂 FK --------------------\n",
    "    if right_joint is not None:\n",
    "        transforms_right, visuals_right = forward_kinematic_single(\n",
    "            joint=right_joint,\n",
    "            joint_cfgs=robot_data.joint_cfgs_right,\n",
    "            is_rad=True,\n",
    "            urdf_file=robot_data.urdf_file_right,\n",
    "            with_visuals_map=True\n",
    "        )\n",
    "        \n",
    "        urdf_dir_right = os.path.dirname(robot_data.urdf_file_right)\n",
    "        \n",
    "        for link_name, transform in transforms_right.items():\n",
    "            for visual in visuals_right.get(link_name, []):\n",
    "                if visual.geom_param is None:\n",
    "                    continue\n",
    "                \n",
    "                mesh_file = visual.geom_param\n",
    "                if isinstance(mesh_file, (list, tuple)):\n",
    "                    mesh_file = mesh_file[0]\n",
    "                \n",
    "                mesh_path = os.path.join(urdf_dir_right, mesh_file)\n",
    "                if not os.path.exists(mesh_path):\n",
    "                    continue\n",
    "                \n",
    "                # 官方双臂右臂变换链 (renderer.py L349-352)\n",
    "                tf = O3D_RENDER_TRANSFORMATION @ \\\n",
    "                     robot_data.camera_to_robot_right @ \\\n",
    "                     ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     RIGHT_ROBOT_PREDEFINED_TRANSFORMATION @ \\\n",
    "                     transform.matrix() @ \\\n",
    "                     visual.offset.matrix()\n",
    "                \n",
    "                mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "                mesh.transform(tf)\n",
    "                mesh.compute_vertex_normals()\n",
    "                mesh.paint_uniform_color([0.9, 0.3, 0.3])\n",
    "                \n",
    "                meshes_right.append({\n",
    "                    'arm': 'right',\n",
    "                    'link_name': link_name,\n",
    "                    'mesh': mesh\n",
    "                })\n",
    "    \n",
    "    print(f\"[INFO] 重建完成: 左臂 {len(meshes_left)} meshes, 右臂 {len(meshes_right)} meshes\")\n",
    "    return meshes_left, meshes_right\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# K3D 可视化 (适配 O3D_RENDER_TRANSFORMATION)\n",
    "# ========================================\n",
    "\n",
    "import k3d\n",
    "\n",
    "def visualize_dual_arm_k3d_official(meshes_left, meshes_right, points_cam=None):\n",
    "    \"\"\"\n",
    "    K3D 可视化,适配官方的 O3D_RENDER_TRANSFORMATION\n",
    "    \n",
    "    注意: meshes 已经应用了 O3D_RENDER_TRANSFORMATION,\n",
    "    所以需要撤销才能在 K3D 中正确显示\n",
    "    \"\"\"\n",
    "    plot = k3d.plot(\n",
    "        grid_visible=True,\n",
    "        background_color=0xffffff,\n",
    "        camera_auto_fit=True\n",
    "    )\n",
    "    \n",
    "    # O3D_RENDER_TRANSFORMATION 的逆变换\n",
    "    # O3D_RENDER = [[1,0,0,0], [0,-1,0,0], [0,0,-1,0], [0,0,0,1]]\n",
    "    # 逆变换就是它自己 (对角矩阵)\n",
    "    inv_o3d_render = O3D_RENDER_TRANSFORMATION\n",
    "    \n",
    "    # 左臂\n",
    "    for item in meshes_left:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        \n",
    "        # 撤销 O3D_RENDER_TRANSFORMATION\n",
    "        verts_h = np.hstack([verts, np.ones((len(verts), 1))])\n",
    "        verts_cam = (inv_o3d_render @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        plot += k3d.mesh(verts_cam, faces, color=0x4D96FF, opacity=0.8)\n",
    "    \n",
    "    # 右臂\n",
    "    for item in meshes_right:\n",
    "        verts = np.asarray(item['mesh'].vertices).astype(np.float32)\n",
    "        faces = np.asarray(item['mesh'].triangles).astype(np.uint32)\n",
    "        \n",
    "        verts_h = np.hstack([verts, np.ones((len(verts), 1))])\n",
    "        verts_cam = (inv_o3d_render @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        plot += k3d.mesh(verts_cam, faces, color=0xFF4D4D, opacity=0.8)\n",
    "    \n",
    "    # 点云 (如果提供)\n",
    "    if points_cam is not None:\n",
    "        colors = np.ones((len(points_cam), 3), dtype=np.uint8) * 128\n",
    "        r = colors[:, 0].astype(np.uint32)\n",
    "        g = colors[:, 1].astype(np.uint32)\n",
    "        b = colors[:, 2].astype(np.uint32)\n",
    "        colors_int = (r << 16) | (g << 8) | b\n",
    "        \n",
    "        plot += k3d.points(\n",
    "            positions=points_cam.astype(np.float32),\n",
    "            colors=colors_int,\n",
    "            point_size=0.004,\n",
    "            shader='flat'\n",
    "        )\n",
    "    \n",
    "    # 坐标轴\n",
    "    axis_len = 0.2\n",
    "    plot += k3d.line([[0,0,0], [axis_len,0,0]], color=0xff0000, width=0.015, name=\"X\")\n",
    "    plot += k3d.line([[0,0,0], [0,axis_len,0]], color=0x00ff00, width=0.015, name=\"Y\")\n",
    "    plot += k3d.line([[0,0,0], [0,0,axis_len]], color=0x0000ff, width=0.015, name=\"Z\")\n",
    "    \n",
    "    plot.display()\n",
    "    return plot\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 执行\n",
    "# ========================================\n",
    "\n",
    "# 1. 恢复原始标定数据 (不交换)\n",
    "robot_data = DualArmRobotData(\n",
    "    lowdim_h5_path=LOWDIM_H5_PATH,\n",
    "    calib_raw=CALIB_RAW,\n",
    "    joint_cfg_left=JOINT_CFG_PATH_LEFT,\n",
    "    joint_cfg_right=JOINT_CFG_PATH_RIGHT,\n",
    "    urdf_left=URDF_FILE_LEFT,\n",
    "    urdf_right=URDF_FILE_RIGHT\n",
    ")\n",
    "\n",
    "# 2. 用官方逻辑重建\n",
    "meshes_left_official, meshes_right_official = reconstruct_dual_arm_at_frame_official(robot_data, 0)\n",
    "\n",
    "# 3. K3D 可视化\n",
    "plot = visualize_dual_arm_k3d_official(meshes_left_official, meshes_right_official)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 渲染 RGB 图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_dual_arm_image(robot_data, meshes_left, meshes_right, width=1280, height=720):\n",
    "    \"\"\"\n",
    "    渲染双臂机器人到 RGB 图像\n",
    "    \"\"\"\n",
    "    print(f\"\\n🎨 渲染双臂 {width}x{height} 图像...\")\n",
    "    \n",
    "    renderer = o3d.visualization.rendering.OffscreenRenderer(width, height)\n",
    "    \n",
    "    material = o3d.visualization.rendering.MaterialRecord()\n",
    "    material.shader = \"defaultLit\"\n",
    "    \n",
    "    # 合并所有网格\n",
    "    all_meshes = meshes_left + meshes_right\n",
    "    \n",
    "    # 添加到场景（变换到相机坐标系）\n",
    "    for i, mesh_data in enumerate(all_meshes):\n",
    "        mesh = mesh_data['mesh']\n",
    "        mesh_copy = o3d.geometry.TriangleMesh(mesh)\n",
    "        \n",
    "        # 变换到相机系\n",
    "        mesh_copy.transform(O3D_RENDER_TRANSFORMATION @ robot_data.world_to_cam)\n",
    "        \n",
    "        renderer.scene.add_geometry(f\"mesh_{i}\", mesh_copy, material)\n",
    "    \n",
    "    # 设置相机\n",
    "    renderer.scene.camera.set_projection(\n",
    "        robot_data.intrinsic_global,\n",
    "        0.01, 100.0,\n",
    "        float(width), float(height)\n",
    "    )\n",
    "    \n",
    "    # 渲染\n",
    "    rgb_image = np.asarray(renderer.render_to_image(), dtype=np.uint8)\n",
    "    depth_image = np.asarray(\n",
    "        renderer.render_to_depth_image(z_in_view_space=True),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ 渲染完成: RGB {rgb_image.shape}, Depth {depth_image.shape}\")\n",
    "    \n",
    "    return rgb_image, depth_image\n",
    "\n",
    "\n",
    "# 渲染双臂\n",
    "rgb_image, depth_image = render_dual_arm_image(robot_data, meshes_left, meshes_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 显示渲染结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# RGB\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rgb_image)\n",
    "plt.title(f\"双臂机器人 RGB 渲染 - Frame {FRAME_IDX}\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Depth\n",
    "plt.subplot(1, 2, 2)\n",
    "depth_vis = depth_image.copy()\n",
    "depth_vis[depth_vis == np.inf] = 0\n",
    "depth_vis = (depth_vis / depth_vis.max() * 255).astype(np.uint8)\n",
    "plt.imshow(depth_vis, cmap='jet')\n",
    "plt.title(f\"深度图 - Frame {FRAME_IDX}\")\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机械臂和点云对照查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "import cv2\n",
    "\n",
    "def debug_dual_arm_alignment_k3d(robot_data, frame_idx, \n",
    "                                  rgb_path_global, depth_path_global,\n",
    "                                  subsample_step=4):\n",
    "    \"\"\"\n",
    "    在 K3D 中同时显示（均在全局相机坐标系下）：\n",
    "    1. 深度图反投影得到的点云（全局相机系）\n",
    "    2. 双臂 FK 机器人模型经 world_to_cam 映射到全局相机系后的 mesh\n",
    "    \n",
    "    参数:\n",
    "        robot_data: DualArmRobotData 对象\n",
    "        frame_idx: 帧索引\n",
    "        rgb_path_global: 全局相机 RGB 图像路径\n",
    "        depth_path_global: 全局相机深度图路径\n",
    "        subsample_step: 点云降采样步长（越大越快）\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== 1. 点云：深度反投影到全局相机系 ==========\n",
    "    print(\"☁️ 生成点云（全局相机坐标系）...\")\n",
    "    \n",
    "    # 加载全局相机图像\n",
    "    color_img = cv2.cvtColor(cv2.imread(rgb_path_global), cv2.COLOR_BGR2RGB)\n",
    "    depth_img = cv2.imread(depth_path_global, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "    \n",
    "    # 获取全局相机内参\n",
    "    K = robot_data.intrinsic_global\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    \n",
    "    # 降采样生成点云\n",
    "    v_idx, u_idx = np.indices(depth_img.shape)\n",
    "    v_idx = v_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    u_idx = u_idx[::subsample_step, ::subsample_step].flatten()\n",
    "    z = depth_img[::subsample_step, ::subsample_step].flatten()\n",
    "    colors = color_img[::subsample_step, ::subsample_step].reshape(-1, 3)\n",
    "    \n",
    "    # 深度过滤\n",
    "    valid_mask = (z > 0) & (z < 2000)  # 0-2000mm\n",
    "    u_idx = u_idx[valid_mask]\n",
    "    v_idx = v_idx[valid_mask]\n",
    "    z = z[valid_mask]\n",
    "    colors = colors[valid_mask]\n",
    "    \n",
    "    # 深度转米（假设深度单位是毫米）\n",
    "    scale = 1000.0\n",
    "    z_m = z / scale\n",
    "    \n",
    "    # 反投影到全局相机坐标系\n",
    "    x_m = (u_idx - cx) * z_m / fx\n",
    "    y_m = (v_idx - cy) * z_m / fy\n",
    "    \n",
    "    points_cam = np.stack([x_m, y_m, z_m], axis=1)\n",
    "    \n",
    "    # 颜色转 K3D 格式\n",
    "    r = colors[:, 0].astype(np.uint32)\n",
    "    g = colors[:, 1].astype(np.uint32)\n",
    "    b = colors[:, 2].astype(np.uint32)\n",
    "    colors_int = (r << 16) | (g << 8) | b\n",
    "    \n",
    "    # ========== 2. 双臂机器人 FK 并映射到全局相机系 ==========\n",
    "    print(\"🤖 FK 计算双臂机器人并映射到全局相机系...\")\n",
    "    \n",
    "    meshes_left, meshes_right = reconstruct_dual_arm_at_frame(robot_data, frame_idx)\n",
    "    \n",
    "    # 世界系 → 全局相机系的变换\n",
    "    world_to_cam = robot_data.world_to_cam\n",
    "    \n",
    "    # ========== 3. K3D 可视化 ==========\n",
    "    print(\"🎨 正在构建 K3D 场景...\")\n",
    "    plot = k3d.plot(\n",
    "        background_color=0xFFFFFF,\n",
    "        grid_visible=True,\n",
    "        camera_auto_fit=True\n",
    "    )\n",
    "    \n",
    "    # A. 点云（全局相机系）\n",
    "    cloud_plt = k3d.points(\n",
    "        positions=points_cam.astype(np.float32),\n",
    "        colors=colors_int.astype(np.uint32),\n",
    "        point_size=0.004,\n",
    "        shader='flat',\n",
    "        name=\"📷 Point Cloud (Global Camera)\"\n",
    "    )\n",
    "    plot += cloud_plt\n",
    "    \n",
    "    # B. 左臂机器人（蓝色）\n",
    "    print(\"🔵 添加左臂到场景...\")\n",
    "    for item in meshes_left:\n",
    "        mesh_o3d = item['mesh']\n",
    "        verts = np.asarray(mesh_o3d.vertices)  # 当前在 URDF Base 系\n",
    "        faces = np.asarray(mesh_o3d.triangles)\n",
    "        \n",
    "        # ✅ 正确变换：URDF Base → Real Base → Camera\n",
    "        # meshes 已经在 URDF Base（包含了 ROBOT_PREDEFINED_TRANSFORMATION）\n",
    "        # 但 camera_to_robot_left 已经包含了 inv(ROBOT_PREDEFINED_TRANSFORMATION)\n",
    "        # 所以变换链：\n",
    "        # 1. 先撤销 ROBOT_PREDEFINED_TRANSFORMATION（回到 URDF Base）\n",
    "        # 2. 应用 robot_to_cam_left（URDF Base → Camera）\n",
    "        \n",
    "        # camera_to_robot_left = ... @ inv(ROBOT_PREDEFINED_TRANSFORMATION)\n",
    "        # robot_to_cam_left = inv(camera_to_robot_left)\n",
    "        # \n",
    "        # 从 URDF Base → Camera:\n",
    "        # URDF Base → Real Base → Camera\n",
    "        # = ROBOT_PREDEFINED_TRANSFORMATION → robot_to_cam_left\n",
    "        \n",
    "        # 但 meshes 已经应用了 ROBOT_PREDEFINED_TRANSFORMATION\n",
    "        # 所以从当前 mesh 到 Camera:\n",
    "        # = inv(ROBOT_PREDEFINED_TRANSFORMATION) @ ROBOT_PREDEFINED_TRANSFORMATION @ robot_to_cam_left\n",
    "        # = robot_to_cam_left\n",
    "        \n",
    "        verts_h = np.hstack([verts, np.ones((len(verts), 1))])\n",
    "        verts_cam = (robot_data.robot_to_cam_left @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        mesh_plt = k3d.mesh(\n",
    "            vertices=verts_cam.astype(np.float32),\n",
    "            indices=faces.astype(np.uint32),\n",
    "            color=0x4D96FF,\n",
    "            opacity=0.8,\n",
    "            name=f\"🔵 LEFT_{item['link_name']}\"\n",
    "        )\n",
    "        plot += mesh_plt\n",
    "\n",
    "    # C. 右臂同理\n",
    "    for item in meshes_right:\n",
    "        mesh_o3d = item['mesh']\n",
    "        verts = np.asarray(mesh_o3d.vertices)\n",
    "        faces = np.asarray(mesh_o3d.triangles)\n",
    "        \n",
    "        verts_h = np.hstack([verts, np.ones((len(verts), 1))])\n",
    "        verts_cam = (robot_data.robot_to_cam_right @ verts_h.T).T[:, :3]\n",
    "        \n",
    "        mesh_plt = k3d.mesh(\n",
    "            vertices=verts_cam.astype(np.float32),\n",
    "            indices=faces.astype(np.uint32),\n",
    "            color=0xFF4D4D,\n",
    "            opacity=0.8,\n",
    "            name=f\"🔴 RIGHT_{item['link_name']}\"\n",
    "        )\n",
    "        plot += mesh_plt\n",
    "    \n",
    "    # D. 坐标轴：全局相机系原点 (X=红, Y=绿, Z=蓝)\n",
    "    axis_len = 0.2\n",
    "    plot += k3d.line([[0,0,0], [axis_len,0,0]], color=0xff0000, width=0.015, name=\"X-axis\")\n",
    "    plot += k3d.line([[0,0,0], [0,axis_len,0]], color=0x00ff00, width=0.015, name=\"Y-axis\")\n",
    "    plot += k3d.line([[0,0,0], [0,0,axis_len]], color=0x0000ff, width=0.015, name=\"Z-axis\")\n",
    "    plot += k3d.points([[0,0,0]], color=0xffff00, point_size=0.03, name=\"Camera Origin\")\n",
    "    \n",
    "    plot.display()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ 完成！双臂机器人与点云对齐可视化\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"📷 灰色点云: 全局相机深度反投影 (真实场景)\")\n",
    "    print(\"🔵 蓝色 Mesh: 左臂机器人 FK 结果\")\n",
    "    print(\"🔴 红色 Mesh: 右臂机器人 FK 结果\")\n",
    "    print(\"🎯 黄色球: 全局相机原点\")\n",
    "    print(\"📐 RGB轴: 全局相机坐标系 (X=红, Y=绿, Z=蓝)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n💡 检查要点:\")\n",
    "    print(\"  1. 点云与 mesh 是否空间位置重合\")\n",
    "    print(\"  2. 左右臂是否在正确位置\")\n",
    "    print(\"  3. 夹爪与物体交互区域是否对齐\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 运行双臂对齐调试\n",
    "# ==============================\n",
    "# 确保路径正确\n",
    "rgb_path_global = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001/cam_105422061350/color/1737546126606.png\"\n",
    "depth_path_global = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001/cam_105422061350/depth/1737546126606.png\"\n",
    "\n",
    "target_idx = 0\n",
    "debug_dual_arm_alignment_k3d(\n",
    "    robot_data, \n",
    "    target_idx, \n",
    "    rgb_path_global, \n",
    "    depth_path_global,\n",
    "    subsample_step=4  # 调整这个参数控制点云密度\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用 RobotRenderer 类 (高级用法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 AirExo-2 的 RobotRenderer 类进行渲染\n",
    "# 注意:这需要双臂配置,但我们可以适配为单臂\n",
    "\n",
    "print(\"\\n🎬 使用 RobotRenderer 类渲染...\")\n",
    "\n",
    "# 创建一个虚拟的右臂配置 (全零)\n",
    "class DummyJointConfig:\n",
    "    def __init__(self):\n",
    "        self.num_joints = 8\n",
    "        self.num_robot_joints = 7\n",
    "\n",
    "renderer = RobotRenderer(\n",
    "    # left_joint_cfgs=DummyJointConfig(), # 虚拟左臂\n",
    "    # right_joint_cfgs=robot_data.joint_cfgs,  \n",
    "    left_joint_cfgs = robot_data.joint_cfgs, \n",
    "    right_joint_cfgs = DummyJointConfig(),\n",
    "    cam_to_base=robot_data.cam_to_base,\n",
    "    intrinsic=robot_data.intrinsic,\n",
    "    width=1280,\n",
    "    height=720,\n",
    "    near_plane=0.01,\n",
    "    far_plane=100.0,\n",
    "    # urdf_file=os.path.join(AIREXO_PATH, \"airexo/urdf_models/robot/robot.urdf\")\n",
    "    urdf_file=\"airexo/urdf_models/robot/robot.urdf\"\n",
    ")\n",
    "\n",
    "# 更新关节状态\n",
    "# right_joint = robot_data.get_joint_at_timestamp(FRAME_IDX)\n",
    "# left_joint = np.zeros(8)  # 虚拟左臂\n",
    "right_joint = np.zeros(8)\n",
    "left_joint = robot_data.get_joint_at_timestamp(FRAME_IDX)\n",
    "\n",
    "\n",
    "renderer.update_joints(left_joint, right_joint)\n",
    "\n",
    "# 渲染\n",
    "rendered_image = renderer.render_image()\n",
    "rendered_depth = renderer.render_depth()\n",
    "\n",
    "# 显示\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(rendered_image)\n",
    "plt.title(\"RobotRenderer - RGB\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "depth_vis = (rendered_depth / rendered_depth.max() * 255).astype(np.uint8)\n",
    "plt.imshow(depth_vis, cmap='jet')\n",
    "plt.title(\"RobotRenderer - Depth\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ RobotRenderer 渲染完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 批量处理多帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_render_frames(robot_data, frame_indices, output_dir=\"./batch_output\"):\n",
    "    \"\"\"\n",
    "    批量渲染多帧\n",
    "    \n",
    "    参数:\n",
    "        robot_data: 数据加载器\n",
    "        frame_indices: 要渲染的帧索引列表\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\n📹 批量渲染 {len(frame_indices)} 帧...\")\n",
    "    \n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        print(f\"\\n[{i+1}/{len(frame_indices)}] 处理帧 {frame_idx}\")\n",
    "        \n",
    "        # 重建\n",
    "        _, _, meshes = reconstruct_robot_at_frame(robot_data, frame_idx)\n",
    "        \n",
    "        # 渲染\n",
    "        rgb, depth = render_robot_image(robot_data, meshes)\n",
    "        \n",
    "        # 保存\n",
    "        output_path = os.path.join(output_dir, f\"frame_{frame_idx:06d}.png\")\n",
    "        Image.fromarray(rgb).save(output_path)\n",
    "        print(f\"  ✓ 已保存: {output_path}\")\n",
    "    \n",
    "    print(f\"\\n✓ 批量渲染完成! 输出目录: {output_dir}\")\n",
    "\n",
    "\n",
    "# 示例: 渲染第 0, 100, 200, 300, 400 帧\n",
    "batch_render_frames(\n",
    "    robot_data,\n",
    "    frame_indices=[0, 100, 200, 300, 400],\n",
    "    output_dir=\"./reconstruction_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 导出完整 3D 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_3d_model(meshes, output_path=\"robot_model.ply\"):\n",
    "    \"\"\"\n",
    "    导出合并后的 3D 模型\n",
    "    \n",
    "    参数:\n",
    "        meshes: 网格列表\n",
    "        output_path: 输出文件路径\n",
    "    \"\"\"\n",
    "    print(f\"\\n💾 导出 3D 模型...\")\n",
    "    \n",
    "    # 合并所有网格\n",
    "    combined_mesh = o3d.geometry.TriangleMesh()\n",
    "    for mesh_data in meshes:\n",
    "        combined_mesh += mesh_data['mesh']\n",
    "    \n",
    "    # 重新计算法线\n",
    "    combined_mesh.compute_vertex_normals()\n",
    "    \n",
    "    # 保存\n",
    "    o3d.io.write_triangle_mesh(output_path, combined_mesh)\n",
    "    \n",
    "    print(f\"✓ 3D 模型已保存: {output_path}\")\n",
    "    print(f\"  - 顶点数: {len(combined_mesh.vertices)}\")\n",
    "    print(f\"  - 三角形数: {len(combined_mesh.triangles)}\")\n",
    "\n",
    "\n",
    "# 导出第 100 帧的 3D 模型\n",
    "export_3d_model(meshes, output_path=f\"robot_frame_{FRAME_IDX}.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本 Notebook 展示了如何使用 AirExo-2 的原生函数从 lowdim 数据重建单臂机器人的 3D 模型:\n",
    "\n",
    "1. ✅ **数据加载**: 从 HDF5 文件读取关节角度和标定数据\n",
    "2. ✅ **正向运动学**: 使用 `forward_kinematic_single` 计算 link 变换\n",
    "3. ✅ **3D 重建**: 加载 URDF 网格并应用变换\n",
    "4. ✅ **可视化**: 使用 Open3D 进行交互式 3D 可视化\n",
    "5. ✅ **渲染**: 使用离屏渲染器生成 RGB 和深度图\n",
    "6. ✅ **批量处理**: 支持多帧批量渲染\n",
    "7. ✅ **模型导出**: 导出 PLY 格式的 3D 模型\n",
    "\n",
    "### 关键技术点\n",
    "\n",
    "- **标定**: pose_in_link 为 7 维 (xyz+四元数)，表示相机在机械臂 base 下的位姿；cam_to_base 为相机系→底座系，base_to_cam 为其逆。\n",
    "- **渲染/对齐**: mesh 在底座系，经 base_to_cam 映射到相机系后与点云（相机系）一致；渲染时变换链为 base_to_cam → O3D_RENDER_TRANSFORMATION。\n",
    "- **关节数据**: 7个机器人关节 (弧度) + 1个夹爪宽度\n",
    "- **URDF 解析**: 使用 `kinpy` 库进行正向运动学\n",
    "- **渲染管线**: Open3D 离屏渲染 + 相机内参投影\n",
    "\n",
    "### 下一步\n",
    "\n",
    "- 🎥 制作动画序列\n",
    "- 🔄 与真实 RGB 图像叠加对比\n",
    "- 📊 分析 TCP 位姿误差\n",
    "- 🎮 集成到数据可视化工具"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airexo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
